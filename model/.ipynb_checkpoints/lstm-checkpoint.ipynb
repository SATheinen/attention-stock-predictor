{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34300ad0-617f-416d-b249-8d7c6b16ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import StudentT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from collections import defaultdict\n",
    "from random import uniform\n",
    "from tqdm import tqdm\n",
    "import scipy.stats\n",
    "from scipy.integrate import quad\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from __future__ import annotations\n",
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932ebf9e-1c66-476d-a016-2f6d8223895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArbitraryMomentumSGD(Optimizer):\n",
    "    def __init__(self, params, lr=required, momentum_schedule=None):\n",
    "        \"\"\"\n",
    "        Custom SGD that accepts arbitrary momentum (can be negative or >1).\n",
    "        \n",
    "        Arguments:\n",
    "        - params: model parameters\n",
    "        - lr: learning rate\n",
    "        - momentum_schedule: callable or float.\n",
    "            If callable: should return momentum given current step.\n",
    "            If float: fixed momentum value.\n",
    "        \"\"\"\n",
    "        defaults = dict(lr=lr, momentum_schedule=momentum_schedule, step=0)\n",
    "        super(ArbitraryMomentumSGD, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\"\"\"\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            lr = group['lr']\n",
    "            step = group['step']\n",
    "            momentum_schedule = group['momentum_schedule']\n",
    "\n",
    "            # Evaluate momentum\n",
    "            if callable(momentum_schedule):\n",
    "                momentum = momentum_schedule(step)\n",
    "            else:\n",
    "                momentum = momentum_schedule\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "\n",
    "                # Initialize velocity if not present\n",
    "                state = self.state[p]\n",
    "                if 'velocity' not in state:\n",
    "                    state['velocity'] = torch.zeros_like(p.data)\n",
    "\n",
    "                v = state['velocity']\n",
    "                v.mul_(momentum).add_(d_p, alpha=-lr)\n",
    "                p.data.add_(v)\n",
    "\n",
    "            # Increment step counter\n",
    "            group['step'] += 1\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bd1b74-f7b5-4c8b-86db-5f22a029c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(x: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Apply sinusoidal embedding to a tensor scaled to [-1, 1].\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape [..., dim]\n",
    "    \"\"\"\n",
    "    assert dim % 2 == 0, \"Embedding dimension must be even\"\n",
    "    orig_shape = x.shape\n",
    "    x = x.unsqueeze(-1)  # [..., 1]\n",
    "\n",
    "    freqs = torch.exp(torch.arange(0, dim, 2, dtype=torch.float32) * (-torch.log(torch.tensor(10000.0)) / dim))\n",
    "    freqs = freqs.to(x.device)  # [dim/2]\n",
    "\n",
    "    angles = x * freqs  # [..., dim/2]\n",
    "    sin = torch.sin(angles)\n",
    "    cos = torch.cos(angles)\n",
    "\n",
    "    embed = torch.cat([sin, cos], dim=-1)  # [..., dim]\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d42598-e227-4903-9d52-1e8bb619e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.dropout(F.relu(self.fc1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a2ffd2-ea88-4934-b52e-f96555fa08bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, asset_size, value_size, seq_len, lstm_layers, num_heads=16, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.A = asset_size\n",
    "        self.V = value_size\n",
    "        self.T = seq_len\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.pre_ffn = PositionwiseFeedForward(d_model, d_model*4, dropout)\n",
    "        self.pre_ffn_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.asset_attn = nn.MultiheadAttention(d_model, num_heads, batch_first=True)\n",
    "        self.asset_attn_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_model*4, dropout)\n",
    "        self.ffn_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        # lstm\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=d_model,\n",
    "            hidden_size=d_model,   # or 2*d_model\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # [B, A*V*T, d_model]\n",
    "        B = x.shape[0]\n",
    "        A = self.A\n",
    "        V = self.V\n",
    "        T = self.T\n",
    "        \n",
    "        # Pre FFN\n",
    "        pre_ffn = self.pre_ffn(x) # [B, A*V*T, d_model]\n",
    "        pre_ffn_norm = self.pre_ffn_norm(x + pre_ffn) # [B, A*V*T, d_model]\n",
    "\n",
    "        # === Self Attention ===\n",
    "        asset = pre_ffn_norm.reshape(B*T, A*V, self.d_model) # [B*T, A*V, d_model]\n",
    "        asset_attn, _ = self.asset_attn(asset, asset, asset) # [B*T, A*V, d_model]\n",
    "        asset_attn_norm = self.asset_attn_norm(asset_attn + asset) # [B*T, A*V, d_model]\n",
    "\n",
    "        # FFN\n",
    "        ffn_reshaped = asset_attn_norm.reshape(B, T, A*V, self.d_model) # [B, T, A*V, d_model]\n",
    "        ffn = self.ffn(ffn_reshaped) # [B, T, A*V, d_model]\n",
    "        ffn_norm = self.ffn_norm(ffn + ffn_reshaped) # [B, T, A*V, d_model]\n",
    "\n",
    "        # LSTM\n",
    "        pre_lstm = ffn_norm.transpose(1, 2) # [B, A*V, T, d_model]\n",
    "        reshape_lstm = pre_lstm.reshape(B*A*V, T, self.d_model)\n",
    "        lstm, (h, c) = self.lstm(reshape_lstm) # [B*A*V, T, d_model]\n",
    "        lstm = lstm.reshape(B, A*V*T, self.d_model) # [B, A*V*T, d_model]\n",
    "        \n",
    "        return x # [B, A*V*T, d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "796046ce-141d-49e1-bdf0-cca2085ab942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, asset_size, value_size, seq_len, bin_centers,\n",
    "                 num_heads=16, lstm_leayers=1, num_transformer_blocks=1, dropout=0.0):\n",
    "\n",
    "        super().__init__()\n",
    "        self.A = asset_size\n",
    "        self.V = value_size\n",
    "        self.T = seq_len\n",
    "        self.bin_centers = bin_centers\n",
    "        self.bin = bin_centers.shape[0]\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # norm\n",
    "        self.x_norm = nn.LayerNorm(d_model)\n",
    "        self.time_norm = nn.LayerNorm(d_model)\n",
    "        self.asset_norm = nn.LayerNorm(d_model)\n",
    "        self.value_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.time_norm2 = nn.LayerNorm(d_model)\n",
    "        self.value_norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # FFN\n",
    "        self.value_ffn = PositionwiseFeedForward(d_model, int(d_model*2), dropout)\n",
    "        self.time_ffn = PositionwiseFeedForward(d_model, int(d_model*2), dropout)\n",
    "\n",
    "        # Learnable ID embeddings\n",
    "        self.asset_embed = nn.Embedding(self.A, d_model)\n",
    "        self.value_embed = nn.Embedding(self.V, d_model)\n",
    "\n",
    "        # Sinusoidal time encoding\n",
    "        self.register_buffer(\"time_pe\", self._build_sinusoidal_pe(self.T, d_model))\n",
    "\n",
    "        # Projection from raw value to d_model\n",
    "        self.value_proj = nn.Linear(1, d_model)\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(d_model, asset_size, value_size, seq_len, lstm_layers, num_heads, dropout) \n",
    "            for _ in range(num_transformer_blocks)\n",
    "        ])\n",
    "\n",
    "        # Output layer\n",
    "        self.time_concat = nn.Linear(seq_len, 1)\n",
    "        self.value_concat = nn.Linear(asset_size * value_size, asset_size)\n",
    "        self.decoder = nn.Linear(d_model, bin_count)\n",
    "\n",
    "    def _build_sinusoidal_pe(self, length, dim):\n",
    "        position = torch.arange(length).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2) * -(torch.log(torch.tensor(10000.0)) / dim))\n",
    "        pe = torch.zeros(length, dim)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe  # shape: [T, d_model]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, A, V, T]\n",
    "        B, A, V, T = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        # === OHLCV input embedding ===\n",
    "        x = x.unsqueeze(-1)  # [B, A, V, T, 1]\n",
    "        x_proj = self.value_proj(x)  # [B, A, V, T, d_model]\n",
    "        x_norm = self.x_norm(x_proj)\n",
    "\n",
    "        # Time embeddings\n",
    "        time_embed = self.time_pe[:T].to(device)  # [T, d_model]\n",
    "        time_embed = time_embed.view(1, 1, 1, T, self.d_model)\n",
    "        time_embed = time_embed.repeat(B, A, V, 1, 1) # [B, A, V, T, d_model]\n",
    "        time_norm = self.time_norm(time_embed)\n",
    "\n",
    "        # Asset embeddings\n",
    "        asset_ids = torch.arange(A, device=device)  # [A]\n",
    "        asset_embed = self.asset_embed(asset_ids)   # [A, d_model]\n",
    "        asset_embed = asset_embed.view(1, A, 1, 1, self.d_model)  # [1, A, 1, 1, d_model]\n",
    "        asset_embed = asset_embed.repeat(B, 1, V, T, 1)      # [B, A, V, T, d_model]\n",
    "        asset_norm = self.asset_norm(asset_embed)\n",
    "        \n",
    "        # Value embeddings\n",
    "        value_ids = torch.arange(V, device=device)  # [V]\n",
    "        value_embed = self.value_embed(value_ids)   # [V, d_model]\n",
    "        value_embed = value_embed.view(1, 1, V, 1, self.d_model)  # [1, 1, V, 1, d_model]\n",
    "        value_embed = value_embed.repeat(B, A, 1, T, 1)      # [B, A, V, T, d_model]\n",
    "        value_norm = self.value_norm(value_embed)\n",
    "\n",
    "        # Final Embedding\n",
    "        x_norm = x_norm + time_norm + asset_norm + value_norm  # [B, A, V, T, d_model]\n",
    "        x_norm = x_norm.reshape(B, A * V * T, self.d_model)  # [B, A*V*T, d_model]\n",
    "\n",
    "        # Transformer LSTM blocks\n",
    "        for layer in self.transformer_blocks:\n",
    "            x_norm = layer(x_norm) # [B, A*V*T, d_model]\n",
    "        post_transformer = x_norm.reshape(B, T, A*V, self.d_model) # [B, T, A*V, d_model]\n",
    "\n",
    "        # Collapse values\n",
    "        value_concat = post_transformer.transpose(2, 3) # [B, T, d_model, A*V]\n",
    "        value_concat = self.value_concat(value_concat) # [B, T, d_model, A]\n",
    "        value_concat = value_concat.transpose(2, 3) # [B, T, A, d_model]\n",
    "\n",
    "        # Value FFN\n",
    "        value_ffn = self.value_ffn(value_concat) # [B, T, A, d_model]\n",
    "        value_norm = self.value_norm2(value_concat + value_ffn) # [B, T, A, d_model]\n",
    "        \n",
    "        # Collapse time\n",
    "        time_concat = value_norm.transpose(1, 3) # [B, d_model, A, T]\n",
    "        time_concat = self.time_concat(time_concat).squeeze(-1) # [B, d_model, A]\n",
    "        time_concat = time_concat.transpose(1, 2)\n",
    "\n",
    "        # Time FFN\n",
    "        time_ffn = self.time_ffn(time_concat) # [B, A, d_model]\n",
    "        time_norm = self.time_norm2(time_concat + time_ffn) # [B, A, d_model]\n",
    "        \n",
    "        # Output\n",
    "        output = self.decoder(time_norm) # [B, A, bins]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baaf8077-a0d4-4d05-a833-6ed96c726fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangular_soft_label(co, lo, hi, bin_centers, temp=1.0):\n",
    "    \"\"\"\n",
    "    Create asymmetric triangular distributions based on observed return range.\n",
    "\n",
    "    Args:\n",
    "        co: [B, A] mode (peak, usually close/open return)\n",
    "        lo: [B, A] lower bound (low/open return)\n",
    "        hi: [B, A] upper bound (high/open return)\n",
    "        bin_centers: [bins] tensor of return bin centers\n",
    "\n",
    "    Returns:\n",
    "        [B, A, bins]: Triangular soft label distribution\n",
    "    \"\"\"\n",
    "    B, A = co.shape\n",
    "    bins = bin_centers.shape[0]\n",
    "\n",
    "    # Ensure valid ranges\n",
    "    lo = torch.min(co, lo)\n",
    "    hi = torch.max(co, hi)\n",
    "\n",
    "    # Expand dimensions for broadcasting\n",
    "    bin_centers = bin_centers.view(1, 1, bins)  # [1,1,bins]\n",
    "    co = co.unsqueeze(-1)  # [B,A,1]\n",
    "    lo = lo.unsqueeze(-1)\n",
    "    hi = hi.unsqueeze(-1)\n",
    "\n",
    "    # Piecewise linear triangular PDF\n",
    "    left_mask = (bin_centers >= lo) & (bin_centers <= co)\n",
    "    right_mask = (bin_centers > co) & (bin_centers <= hi)\n",
    "\n",
    "    left_vals = (bin_centers - lo) / (co - lo + 1e-8)\n",
    "    right_vals = (hi - bin_centers) / (hi - co + 1e-8)\n",
    "\n",
    "    pdf = torch.where(left_mask, left_vals, torch.zeros_like(left_vals))\n",
    "    pdf = torch.where(right_mask, right_vals, pdf)\n",
    "\n",
    "    # Normalize so sum=1\n",
    "    probs = F.softmax(pdf / temp, dim=-1)\n",
    "\n",
    "    return probs  # [B, A, bins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4eabaa7-19e7-4acd-bb89-545774d3707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(pred_probs, target_probs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pred_probs: [B, A, bins] tensor from softmax\n",
    "        target_probs: [B, A, bins] tensor from triangular_soft_label\n",
    "\n",
    "    Returns:\n",
    "        Scalar loss: mean Wasserstein distance across [B, A]\n",
    "    \"\"\"\n",
    "    cdf_pred = torch.cumsum(pred_probs, dim=-1)     # [B, A, bins]\n",
    "    cdf_target = torch.cumsum(target_probs, dim=-1) # [B, A, bins]\n",
    "    w1 = torch.abs(cdf_pred - cdf_target).sum(dim=-1)  # [B, A]\n",
    "    return w1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e01c2b5-9eec-4978-b90b-e7d57966afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset():\n",
    "    def __init__(self, root_dir, seq_len=1024, num_days=1):\n",
    "        self.seq_len = seq_len\n",
    "        self.num_days = num_days\n",
    "        self.root_dir = root_dir\n",
    "        self.files = self.get_filenames()\n",
    "        self.data = self.load_data()\n",
    "\n",
    "    def get_filenames(self):\n",
    "        files = os.listdir(self.root_dir)\n",
    "        return files\n",
    "    \n",
    "    def load_data(self):\n",
    "        # Array of dimension [stock name, price category(open, close, high, low, close, volume, date), sequence length]\n",
    "        data = np.zeros((len(self.files), 13, self.seq_len // self.num_days))\n",
    "        \n",
    "        for i, filename in enumerate(self.files):\n",
    "            \n",
    "            with open(self.root_dir + '/' + filename, 'r', encoding=\"utf-8\") as file:\n",
    "                #print(filename)\n",
    "                #head = file.read(1000)\n",
    "                #print(head)  # if this looks binary, it's not a JSON file!\n",
    "                file.seek(0)\n",
    "                content = json.load(file)\n",
    "                time_series = content[\"Time Series (Daily)\"]\n",
    "\n",
    "                df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "                df.columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "                o = df[['open']].to_numpy()\n",
    "                c = df[['close']].to_numpy()\n",
    "                h = df[['high']].to_numpy()\n",
    "                l = df[['low']].to_numpy()\n",
    "                v = df[['volume']].to_numpy()\n",
    "                t = df.index.to_numpy()\n",
    "\n",
    "                # All data is aranged from oldest to newest date\n",
    "                # So we first have to flip the data by [::-1]\n",
    "                # Percentage change r\n",
    "                \n",
    "                # O[t + 1] / O[t]\n",
    "                data[i, 0, :] = (o.flatten()[:self.seq_len][::-1][::self.num_days] /\n",
    "                                 o.flatten()[self.num_days:self.seq_len + self.num_days][::-1][::self.num_days]) -1\n",
    "                # C[t + 1] / C[t]\n",
    "                data[i, 1, :] = (c.flatten()[:self.seq_len][::-1][::self.num_days] /\n",
    "                                 c.flatten()[self.num_days:self.seq_len + self.num_days][::-1][::self.num_days]) -1\n",
    "                # H[t + 1] / H[t]\n",
    "                data[i, 2, :] = (h.flatten()[:self.seq_len][::-1][::self.num_days] /\n",
    "                                 h.flatten()[self.num_days:self.seq_len + self.num_days][::-1][::self.num_days]) -1\n",
    "                # L[t + 1] / L[t]\n",
    "                data[i, 3, :] = (l.flatten()[:self.seq_len][::-1][::self.num_days] /\n",
    "                                 l.flatten()[self.num_days:self.seq_len + self.num_days][::-1][::self.num_days]) -1\n",
    "                # O[t + 1] / C[t]\n",
    "                data[i, 5, :] = (o.flatten()[:self.seq_len][::-1][::self.num_days] /\n",
    "                                 c.flatten()[self.num_days:self.seq_len + self.num_days][::-1][::self.num_days]) -1\n",
    "                # H[t + 1] / C[t]\n",
    "                data[i, 6, :] = (h.flatten()[:self.seq_len][::-1][::self.num_days] /\n",
    "                                 c.flatten()[self.num_days:self.seq_len + self.num_days][::-1][::self.num_days]) -1\n",
    "                # L[t + 1] / C[t]\n",
    "                data[i, 7, :] = (l.flatten()[:self.seq_len][::-1][::self.num_days] /\n",
    "                                 c.flatten()[self.num_days:self.seq_len + self.num_days][::-1][::self.num_days]) -1\n",
    "                # C[t + 1] / O[t + 1]\n",
    "                data[i, 8, :] = (c.flatten()[:self.seq_len][::-1][::self.num_days] /\n",
    "                                 o.flatten()[self.num_days -1:self.seq_len + self.num_days -1][::-1][::self.num_days]) -1\n",
    "                # H[t + 1] / O[t + 1]\n",
    "                data[i, 9, :] = (h.flatten()[:self.seq_len][::-1][::self.num_days] /\n",
    "                                 o.flatten()[self.num_days -1:self.seq_len + self.num_days -1][::-1][::self.num_days]) -1\n",
    "                # L[t + 1] / O[t + 1]\n",
    "                data[i, 10, :] = (l.flatten()[:self.seq_len][::-1][::self.num_days] /\n",
    "                                 o.flatten()[self.num_days -1:self.seq_len + self.num_days -1][::-1][::self.num_days]) -1\n",
    "                # log(1 + V)\n",
    "                data[i, 11, :] = np.log(1 + v.flatten()[:self.seq_len][::-1][::self.num_days])\n",
    "\n",
    "                # convert date to unix time\n",
    "                dates = t.flatten()[:self.seq_len][::-1][::self.num_days]\n",
    "                data[i, 12, :] = dates.astype('datetime64[s]')\n",
    "                data[i, 12, :] = data[i, 7, :].astype('int64')\n",
    "\n",
    "                file.close()\n",
    "\n",
    "            # extra statistics\n",
    "            data[:, 4, :] = data[:, 2, :] - data[:, 3, :] # daily range high - low\n",
    "    \n",
    "        return data\n",
    "\n",
    "    def average(self, decay_fac=0.0):\n",
    "        \n",
    "        avg_arr = np.zeros_like(self.data)\n",
    "        \n",
    "        for i in range(self.seq_len):\n",
    "            exp_decay = np.exp(-decay_fac * np.arange(0, self.seq_len - i))\n",
    "            exp_decay = exp_decay[::-1]\n",
    "            exp_decay = np.expand_dims(exp_decay, axis=0)\n",
    "            exp_decay = np.expand_dims(exp_decay, axis=0)\n",
    "            exp_decay = np.repeat(exp_decay, repeats=len(self.files), axis=0)\n",
    "            exp_decay = np.repeat(exp_decay, repeats=5, axis=1)\n",
    "            avg_arr[:,:-1,i] = np.sum(self.data[:,:-1,i:] * exp_decay, axis=-1) / np.sum(exp_decay[:,:,:], axis=-1)\n",
    "        \n",
    "        avg_arr[:,-1,:] = self.data[:,-1,:].copy()\n",
    "\n",
    "        return avg_arr\n",
    "\n",
    "    def recons_absol(self):\n",
    "        # this function only provides a test to reconstruct the original shape of the stock prices\n",
    "        abs_data = np.zeros_like(self.data)\n",
    "        abs_data[:,:,0] = 1.\n",
    "        abs_data[:,-1,:] = self.data[:,-1,:]\n",
    "        # iterate over all timesteps after the first\n",
    "        for j in range(self.data.shape[2] - 1):\n",
    "            abs_data[:, :-1, j+1] = abs_data[:, :-1, j] * (1 + self.data[:, :-1, j])\n",
    "\n",
    "        return abs_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baf221e6-1961-432e-8573-4ddd1243f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_len, max_deviation=100.):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.seq_len = seq_len\n",
    "        self.max_deviation = max_deviation\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[-1] -self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[:, :, idx : idx + self.seq_len]\n",
    "        \n",
    "        # Mask extreme input data !!! Not Target !!!\n",
    "        #mask = torch.where(torch.abs(x) > self.max_deviation, 0.0, 1.0)\n",
    "        #x = x * mask\n",
    "        \n",
    "        y = self.data[:, 5:8, idx + self.seq_len]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f86ed9d-f7bf-483b-995c-9792f1b2a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series(data, train_ratio=0.5, val_ratio=0.25):\n",
    "    time_steps = data.shape[-1]\n",
    "    #print(f\"Time steps: {time_steps}\")\n",
    "    train_end = int(time_steps * train_ratio)\n",
    "    val_end = int(time_steps * (train_ratio + val_ratio))\n",
    "    return data[:, :, 0:train_end], data[:, :, train_end:val_end], data[:, :, val_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da0b2f04-c713-41d2-a37c-3881f3bb7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warmup_cosine_scheduler(optimizer, warmup_steps, plateau_steps, total_steps, lr_max):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return current_step / warmup_steps\n",
    "        elif (current_step >= warmup_steps) & (current_step <  warmup_steps + plateau_steps):\n",
    "            return 1.0\n",
    "        else:\n",
    "            progress = (current_step - warmup_steps - plateau_steps) / (total_steps - warmup_steps - plateau_steps)\n",
    "            return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73d3ccc8-335f-4b2a-9256-c9835e0937a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cyclic_momentum(step):\n",
    "    return 0.5 + 0.5 * np.cos(2 * np.pi * step / 60)\n",
    "\n",
    "dummy_warmup_steps = 5\n",
    "dummy_plateau_steps = 1\n",
    "dummy_total_steps = 30\n",
    "dummy_lr = np.zeros(dummy_total_steps)\n",
    "dummy_momentum = np.zeros(dummy_total_steps)\n",
    "dummy_steps = np.arange(0, dummy_total_steps, 1)\n",
    "\n",
    "for step in dummy_steps:\n",
    "    \n",
    "    if step < dummy_warmup_steps:\n",
    "        dummy_lr[step] = step / dummy_warmup_steps\n",
    "    elif (step >= dummy_warmup_steps) & (step < dummy_warmup_steps + dummy_plateau_steps):\n",
    "        dummy_lr[step] = 1.0\n",
    "    else:\n",
    "        progress = (step - dummy_warmup_steps - dummy_plateau_steps) / (dummy_total_steps - dummy_warmup_steps - dummy_plateau_steps)\n",
    "        dummy_lr[step] = 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "    dummy_momentum[step] = cyclic_momentum(step)\n",
    "\n",
    "plt.plot(dummy_steps, dummy_lr)\n",
    "plt.plot(dummy_steps, dummy_momentum)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77f97ff2-8da7-456c-84b2-26c96453bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alloc_return(\n",
    "    preds, real_returns, bin_centers,\n",
    "    cash_threshold=0.5,\n",
    "    temp=0.01,\n",
    "    apply_confidence_mask=True,\n",
    "    min_prob=0.5,\n",
    "    allow_leverage=False,\n",
    "    x_grid_points=10000\n",
    "):\n",
    "    \"\"\"\n",
    "    preds : [B, A, bin_cound]\n",
    "    real_returns : [B, A]\n",
    "    bin_centers : [bin_counts]\n",
    "    \"\"\"\n",
    "    \n",
    "    B, A, bin_count = preds.shape # [B, A, bin_counts]\n",
    "    device = preds.device\n",
    "\n",
    "    # Add synthetic 'cash' asset\n",
    "    #real_returns = torch.cat([real_returns, torch.zeros(B, 1, device=device)], dim=1)\n",
    "    \n",
    "    # calculate the probability to predict the correct direction\n",
    "    pos_prob = (preds * (bin_centers > 0).float()).sum(-1) # [B, A]\n",
    "\n",
    "    # calculate the expected increase\n",
    "    exp_gain = torch.sum(preds * bin_centers[None, None, :], axis=-1)  # [B, A]\n",
    "\n",
    "    # compute optimal Leverage\n",
    "    if allow_leverage:\n",
    "        \n",
    "        # calculate optimal lever\n",
    "        optimal_leverage = kelly(\n",
    "            preds, bin_centers, cost=0.0, l_bounds=(-10, 10), \n",
    "            frac_kelly=1.0, iters=100, tol=1e-8\n",
    "        )\n",
    "        \n",
    "        # Adjust negative gains to short sell logic\n",
    "        exp_gain = torch.where(exp_gain > 0, exp_gain, 1 / (1 + exp_gain) - 1)\n",
    "        exp_gain *= torch.abs(optimal_leverage)\n",
    "\n",
    "        # calculate the probability to predict the correct direction\n",
    "        neg_prob = (preds * (bin_centers < 0).float()).sum(-1) # [B, A]\n",
    "        pos_prob = torch.where(optimal_leverage < 0, neg_prob, pos_prob)\n",
    "\n",
    "        # use only strong datapoints with absolute leverage > 1\n",
    "        #optimal_leverage = torch.where(torch.abs(optimal_leverage) >= 1, optimal_leverage, 0)\n",
    "    else:\n",
    "        optimal_leverage = torch.zeros((B, A)) + 1\n",
    "\n",
    "    # Add cash hold asset\n",
    "    #preds = torch.cat([preds, torch.zeros(B, 1, bin_count, device=device)], dim=1)\n",
    "\n",
    "    # No leverage for cash hold\n",
    "    #optimal_leverage[:, -1] = 0 # [B, 1]\n",
    "\n",
    "    # sort out low confidence predictions\n",
    "    if apply_confidence_mask:\n",
    "        exp_gain *= (pos_prob > min_prob).float()\n",
    "\n",
    "    # Cash threshold handling\n",
    "    #exp_gain[:, -1] = cash_threshold\n",
    "    \n",
    "    # Softmax allocation based on confidence\n",
    "    alloc_raw = F.softmax(exp_gain / temp, dim=-1)  # [B, A]\n",
    "\n",
    "    single_returns = alloc_raw * real_returns * optimal_leverage # [B, A]\n",
    "    port_ret = single_returns.sum(dim=1)  # [B]\n",
    "\n",
    "    return alloc_raw, port_ret, single_returns, optimal_leverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9bd9057-bc5e-48cf-8d71-f47d359d89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bootstrap_metrics(returns: torch.Tensor, n_bootstrap: int = 1000, ci: float = 0.95):\n",
    "    \"\"\"\n",
    "    Compute bootstrapped performance metrics (CI) using torch.\n",
    "    \n",
    "    Args:\n",
    "        returns (torch.Tensor): 1D tensor of daily returns.\n",
    "        n_bootstrap (int): Number of bootstrap samples.\n",
    "        ci (float): Confidence interval (e.g. 0.95).\n",
    "    \n",
    "    Returns:\n",
    "        dict: {metric: (mean, lower_ci, upper_ci)}\n",
    "    \"\"\"\n",
    "    assert returns.dim() == 1, \"Returns must be 1D\"\n",
    "    returns = returns.detach()\n",
    "    device = returns.device\n",
    "    N = returns.shape[0]\n",
    "    alpha = 1 - ci\n",
    "\n",
    "    metrics = {\n",
    "        'daily_return': [],\n",
    "        'cumulative_return': [],\n",
    "        'annualized_return': [],\n",
    "        'sharpe_ratio': [],\n",
    "        'max_drawdown': []\n",
    "    }\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Resample with replacement\n",
    "        idx = torch.randint(0, N, (N,), device=device)\n",
    "        sample = returns[idx]\n",
    "\n",
    "        mean_r = sample.mean()\n",
    "        std_r = sample.std(unbiased=False)\n",
    "        sharpe = mean_r / (std_r + 1e-8) * torch.sqrt(torch.tensor(252.0, device=device))\n",
    "\n",
    "        equity = torch.cumprod(1 + sample, dim=0)\n",
    "        cum_return = equity[-1] - 1\n",
    "        annual_ret = equity[-1].pow(252.0 / N * num_days) - 1\n",
    "\n",
    "        peak = torch.cummax(equity, dim=0)[0]\n",
    "        drawdown = (equity - peak) / (peak + 1e-8)\n",
    "        max_dd = drawdown.min()\n",
    "\n",
    "        metrics['daily_return'].append(mean_r.item())\n",
    "        metrics['cumulative_return'].append(cum_return.item())\n",
    "        metrics['annualized_return'].append(annual_ret.item())\n",
    "        metrics['sharpe_ratio'].append(sharpe.item())\n",
    "        metrics['max_drawdown'].append(max_dd.item())\n",
    "\n",
    "    def summarize(values: list[float]):\n",
    "        values = torch.tensor(values)\n",
    "        mean = values.mean().item()\n",
    "        lower = values.kthvalue(int((alpha / 2) * n_bootstrap))[0].item()\n",
    "        upper = values.kthvalue(int((1 - alpha / 2) * n_bootstrap))[0].item()\n",
    "        return mean, lower, upper\n",
    "\n",
    "    return {k: summarize(v) for k, v in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a878a6-4abe-4974-9e58-e647c1436dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_performance_metrics(returns: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Differentiable performance metrics using PyTorch ops.\n",
    "    Assumes returns are daily returns as a 1D tensor.\n",
    "    \"\"\"\n",
    "    # Ensure shape [N]\n",
    "    returns = returns.view(-1)\n",
    "\n",
    "    # Cumulative equity curve\n",
    "    equity_curve = torch.cumprod(1 + returns, dim=0)\n",
    "\n",
    "    # Annualized return\n",
    "    total_return = equity_curve[-1]\n",
    "    annualized_return = total_return.pow(252 / (returns.size(0) * num_days)) - 1\n",
    "\n",
    "    # Sharpe ratio (risk-free rate = 0)\n",
    "    sharpe_ratio = returns.mean() / (returns.std(unbiased=False) + 1e-8) * torch.sqrt(torch.tensor(252.0 / num_days, device=returns.device))\n",
    "\n",
    "    # Max drawdown\n",
    "    rolling_max, _ = torch.cummax(equity_curve, dim=0)\n",
    "    drawdowns = (equity_curve - rolling_max) / (rolling_max + 1e-8)\n",
    "    max_drawdown = drawdowns.min()\n",
    "\n",
    "    return sharpe_ratio, max_drawdown, annualized_return, equity_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "236d20ac-1757-430b-8898-aa1350480ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def kelly(\n",
    "    preds: torch.Tensor,\n",
    "    bin_centers: torch.Tensor,\n",
    "    cost: float = 0.0,\n",
    "    l_bounds: Tuple[float, float] = (-10.0, 10.0),\n",
    "    frac_kelly: float = 1.0,\n",
    "    iters: int = 60,\n",
    "    tol: float = 1e-8,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute optimal leverage L per asset using Kelly criterion.\n",
    "\n",
    "    Args:\n",
    "        preds: [B, A, bins] probability distribution over returns\n",
    "        bin_centers: [bins] tensor of return bin centers\n",
    "        cost: scalar transaction cost\n",
    "        l_bounds: search interval for leverage (lo, hi)\n",
    "        frac_kelly: scale final solution (e.g. 0.5 Kelly)\n",
    "        iters: max bisection iterations\n",
    "        tol: stopping tolerance\n",
    "\n",
    "    Returns:\n",
    "        [B, A] tensor of optimal leverage values\n",
    "    \"\"\"\n",
    "    B, A, bins = preds.shape\n",
    "    device, dtype = preds.device, preds.dtype\n",
    "\n",
    "    # Adjust returns for cost\n",
    "    y = (bin_centers - cost).to(device=device, dtype=dtype)  # [bins]\n",
    "\n",
    "    def f_of_L(L):\n",
    "        denom = 1.0 + y[None, None, :] * L[..., None]\n",
    "        integrand = (y[None, None, :] / denom) * preds\n",
    "        return torch.trapz(integrand, y, dim=-1)   # integrate wrt y\n",
    "\n",
    "    # Initialize brackets\n",
    "    L_left = torch.full((B, A), l_bounds[0], device=device, dtype=dtype)\n",
    "    L_right = torch.full((B, A), l_bounds[1], device=device, dtype=dtype)\n",
    "\n",
    "    f_left = f_of_L(L_left)\n",
    "    f_right = f_of_L(L_right)\n",
    "\n",
    "    # If no root in bracket, choose boundary\n",
    "    no_root_low = (f_left < 0) & (f_right < 0)\n",
    "    no_root_high = (f_left > 0) & (f_right > 0)\n",
    "    root_mask = ~(no_root_low | no_root_high)\n",
    "\n",
    "    L_star = torch.where(no_root_low, L_left, torch.where(no_root_high, L_right, 0.5 * (L_left + L_right)))\n",
    "\n",
    "    a, b = L_left.clone(), L_right.clone()\n",
    "    fa, fb = f_left.clone(), f_right.clone()\n",
    "\n",
    "    for _ in range(iters):\n",
    "        if not root_mask.any():\n",
    "            break\n",
    "\n",
    "        m = 0.5 * (a + b)\n",
    "        fm = f_of_L(m)\n",
    "\n",
    "        left_side = (fa * fm > 0) & root_mask\n",
    "        a[left_side] = m[left_side]\n",
    "        fa[left_side] = fm[left_side]\n",
    "\n",
    "        right_side = (~left_side) & root_mask\n",
    "        b[right_side] = m[right_side]\n",
    "        fb[right_side] = fm[right_side]\n",
    "\n",
    "        L_star[root_mask] = 0.5 * (a[root_mask] + b[root_mask])\n",
    "\n",
    "        if (b - a).abs()[root_mask].max() < tol:\n",
    "            break\n",
    "\n",
    "    return frac_kelly * L_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "772d80f0-0d4f-4cfc-a752-edcb6dae7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "num_days = 1 # How many days is each datapoint?\n",
    "data_seq_len = 300 # How many days are considered in the dataset\n",
    "\n",
    "train_ratio = 0.4 # data ratio used for training\n",
    "val_ratio = 0.3 # data ratio used for validating (the remaining data is used for test)\n",
    "max_deviation = 100.0 # Mask extreme data\n",
    "\n",
    "# model parameters\n",
    "d_model = 128\n",
    "num_heads = 16 # attention heads\n",
    "dropout = 0.3\n",
    "seq_len = 18 # Time steps in input sequence\n",
    "batch_size = 1 # batch size (do not change)\n",
    "bin_count = 100 # granularity of predicted probability distribution\n",
    "bin_border = 0.1\n",
    "num_transformer_blocks = 5\n",
    "lstm_layers = 3\n",
    "\n",
    "num_experts = 1\n",
    "\n",
    "# Target smearing\n",
    "triangle_temp = 0.1\n",
    "\n",
    "# Transformer output temp\n",
    "trans_temp = 0.1\n",
    "\n",
    "# training main model\n",
    "warmup_steps = 2\n",
    "plateau_steps = 1\n",
    "total_steps = 5\n",
    "lr_max=1e-6\n",
    "weight_decay = 0.0\n",
    "momentum_cycle = 2 * total_steps * (int(train_ratio * data_seq_len - seq_len))\n",
    "static_momentum = 0.8\n",
    "periodic_momentum = 0.0\n",
    "\n",
    "\n",
    "bin_centers = torch.linspace(-bin_border, bin_border, bin_count)\n",
    "bin_centers = torch.exp(bin_centers) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcc2e7c7-a241-446d-9836-df1b92c7c743",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (300,) (299,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/silas/work/machine_learning/LSTM/data/data_dump\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#root_dir = \"/Users/silas/work/machine_learning/LSTM/data/my_repo\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m stock_data \u001b[38;5;241m=\u001b[39m \u001b[43mStockDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_seq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_days\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m stock_nr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      6\u001b[0m stock_names \u001b[38;5;241m=\u001b[39m [name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m stock_data\u001b[38;5;241m.\u001b[39mfiles]\n",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36mStockDataset.__init__\u001b[0;34m(self, root_dir, seq_len, num_days)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir \u001b[38;5;241m=\u001b[39m root_dir\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_filenames()\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 56\u001b[0m, in \u001b[0;36mStockDataset.load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m data[i, \u001b[38;5;241m3\u001b[39m, :] \u001b[38;5;241m=\u001b[39m (l\u001b[38;5;241m.\u001b[39mflatten()[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_days] \u001b[38;5;241m/\u001b[39m\n\u001b[1;32m     54\u001b[0m                  l\u001b[38;5;241m.\u001b[39mflatten()[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_days:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_days][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_days]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# O[t + 1] / C[t]\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m data[i, \u001b[38;5;241m5\u001b[39m, :] \u001b[38;5;241m=\u001b[39m (\u001b[43mo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_days\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_days\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_days\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_days\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# H[t + 1] / C[t]\u001b[39;00m\n\u001b[1;32m     59\u001b[0m data[i, \u001b[38;5;241m6\u001b[39m, :] \u001b[38;5;241m=\u001b[39m (h\u001b[38;5;241m.\u001b[39mflatten()[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_days] \u001b[38;5;241m/\u001b[39m\n\u001b[1;32m     60\u001b[0m                  c\u001b[38;5;241m.\u001b[39mflatten()[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_days:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_days \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][::\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_days]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (300,) (299,) "
     ]
    }
   ],
   "source": [
    "root_dir = \"/Users/silas/work/machine_learning/LSTM/data/data_dump\"\n",
    "#root_dir = \"/Users/silas/work/machine_learning/LSTM/data/my_repo\"\n",
    "stock_data = StockDataset(root_dir, seq_len=data_seq_len, num_days=num_days)\n",
    "\n",
    "stock_nr = 3\n",
    "stock_names = [name.split(\".\")[0] for name in stock_data.files]\n",
    "print(f\"Stock names: {stock_names}\")\n",
    "\n",
    "num_stocks = len(stock_data.files)\n",
    "print(f\"num stocks: {num_stocks}\")\n",
    "print()\n",
    "\n",
    "abs_data = stock_data.recons_absol()\n",
    "x = np.linspace(0, len(abs_data[stock_nr,-1,:]), len(abs_data[stock_nr,-1,:]))\n",
    "y = np.mean(abs_data[:,0,:], axis=0)\n",
    "\n",
    "val_idx = int(train_ratio*len(x))\n",
    "test_idx = int((train_ratio + val_ratio)*len(x))\n",
    "\n",
    "val_cut = x[val_idx]\n",
    "test_cut = x[test_idx]\n",
    "\n",
    "train_data = y[:val_idx]\n",
    "val_data = y[val_idx:test_idx]\n",
    "test_data = y[test_idx:]\n",
    "\n",
    "for arr, text in zip([train_data, val_data, test_data], [\"Train     \", \"Validation\", \"Test      \"]):\n",
    "    interval_return = arr[-1] / arr[0] -1\n",
    "    print(f\"Interval return {text}: {interval_return:.2%}\")\n",
    "\n",
    "print()\n",
    "for arr, text in zip([train_data, val_data, test_data], [\"Train     \", \"Validation\", \"Test      \"]):\n",
    "    buy_and_hold = arr[-1] / arr[seq_len] -1\n",
    "    print(f\"Trainig window adjusted return {text}: {buy_and_hold:.2%}\")\n",
    "    \n",
    "plt.plot(x, y, color=\"blue\")\n",
    "plt.grid()\n",
    "plt.vlines([val_cut, test_cut], np.min(y) - 0.1, np.max(y) + 0.1, color=\"black\") # train/val/test split\n",
    "plt.vlines([val_cut + seq_len, test_cut + seq_len], np.min(y) - 0.1, np.max(y) + 0.1, color=\"red\") # window adjusted train/val/test split\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66463370-f7f9-4a92-9aed-d963481a39c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stock_data.data[:,:12,:] # Pass OHLC\n",
    "\n",
    "# [open, close, high, low, c/o, h/o, l/o, high - low, close-open, volume]\n",
    "\n",
    "value_size = data.shape[1]\n",
    "in_size = len(stock_data.files) # number of stocks\n",
    "\n",
    "print(f\"Stock dimension: {stock_data.data.shape}\")\n",
    "print(f\"Value size: {value_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816cf1fc-e09c-431b-9c04-1ad6d92cb9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "#### Data #####\n",
    "###############\n",
    "train, val, test = split_time_series(data, train_ratio=train_ratio, val_ratio=val_ratio)\n",
    "print(f\"Shapes: train={train.shape} val={val.shape} test={test.shape}\")\n",
    "\n",
    "train_ds = TimeSeriesDataset(train, seq_len, max_deviation)\n",
    "val_ds = TimeSeriesDataset(val, seq_len, max_deviation)\n",
    "test_ds = TimeSeriesDataset(test, seq_len, max_deviation)\n",
    "#print(f\"Shapes: train={train.shape} val={val.shape} test={test.shape}\")\n",
    "\n",
    "# (Batch, in_size, seq_len)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac5b04-acd6-4299-b9be-26dabf0ba788",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70043128-d186-4136-a5ed-1fa3cfa45ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(d_model, in_size, value_size, seq_len, bin_centers,\n",
    "                    num_heads, lstm_layers, num_transformer_blocks, dropout=dropout).to(device)\n",
    "\n",
    "params = [p for n, p in model.named_parameters()]\n",
    "\n",
    "optimizer = ArbitraryMomentumSGD(\n",
    "    [\n",
    "        {\"params\": params, \"lr\": lr_max},          # default LR\n",
    "    ],\n",
    "    momentum_schedule=lambda step: static_momentum\n",
    "        + periodic_momentum * torch.cos(\n",
    "            2 * torch.pi * torch.tensor(step) / torch.tensor(momentum_cycle)\n",
    "        )\n",
    ")\n",
    "\n",
    "scheduler = get_warmup_cosine_scheduler(\n",
    "    optimizer, warmup_steps=warmup_steps, plateau_steps=plateau_steps, total_steps=total_steps, lr_max=lr_max\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4e12e-16a5-4f92-8fe4-9b897d711ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bin_centers = bin_centers.clone()  # coarse bins for clarity\n",
    "co = torch.tensor([[0.0]])\n",
    "lo = torch.tensor([[-0.01]])\n",
    "hi = torch.tensor([[0.01]])\n",
    "\n",
    "for temp in [0.5, 1.0, 2.0]:\n",
    "    probs = triangular_soft_label(co, lo, hi, test_bin_centers, temp=temp)\n",
    "    plt.plot(test_bin_centers.numpy(), probs[0, 0].numpy(), label=f\"temp={temp}\")\n",
    "\n",
    "plt.title(\"Test Triangular Soft Label Distribution\")\n",
    "plt.xlabel(\"Bin Centers\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for batch_x, batch_y in train_loader:\n",
    "            \n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.to(device)\n",
    "\n",
    "    co = batch_y[:, :, 0] # [B, A]\n",
    "    hi = batch_y[:, :, 1]\n",
    "    lo = batch_y[:, :, 2]\n",
    "\n",
    "    target_probs = triangular_soft_label(co, lo, hi, test_bin_centers, temp=triangle_temp)  # [B, A, bins]\n",
    "    target_probs = target_probs.detach().cpu().numpy()\n",
    "\n",
    "    single_asset = target_probs[0, 5, :] # [bins]\n",
    "    plt.plot(test_bin_centers.numpy(), single_asset)\n",
    "    plt.ylim(-0.001)\n",
    "\n",
    "    plt.title(\"Real Data Triangular Soft Label Distribution\")\n",
    "    plt.xlabel(\"Bin Centers\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(np.sum(single_asset))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26955d0c-8565-4984-90d7-7a4658bf64f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################\n",
    "#### Training ####\n",
    "##################\n",
    "\n",
    "# Set some parameters for the calc_alloc_return function\n",
    "train_cash_threshold = 0.0\n",
    "train_temp = 0.005\n",
    "train_min_prob = 0.5\n",
    "allow_leverage=False\n",
    "\n",
    "returns_buffer = []\n",
    "\n",
    "# Train LSTM model\n",
    "for train_step in range(total_steps):\n",
    "        \n",
    "    all_train_losses = []\n",
    "    all_val_losses = []\n",
    "\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "            \n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        B, A, V, T = batch_x.shape\n",
    "\n",
    "        #if perm_counter % 5 == 0:\n",
    "            # Generate a random permutation of assets\n",
    "        perm = torch.randperm(A, device=batch_x.device)\n",
    "        \n",
    "        # Apply same permutation to both tensors along dim=1\n",
    "        batch_x = batch_x[:, perm, :, :]\n",
    "        batch_y = batch_y[:, perm]\n",
    "\n",
    "        # train stock predictor\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred_probs = model(batch_x) # [B, A, bins]\n",
    "        pred_probs = F.softmax(pred_probs / trans_temp, dim=-1)\n",
    "\n",
    "        co = batch_y[:, :, 0] # [B, A]\n",
    "        hi = batch_y[:, :, 1]\n",
    "        lo = batch_y[:, :, 2]\n",
    "\n",
    "        target_probs = triangular_soft_label(co, lo, hi, bin_centers, triangle_temp)  # [B, A, bins]\n",
    "        \n",
    "        loss = wasserstein_loss(pred_probs, target_probs)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.5)\n",
    "    \n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "\n",
    "        #perm_counter += 1\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader) / in_size\n",
    "\n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "\n",
    "    returns_buffer = []\n",
    "    total_ret, sample_count = 0, 0\n",
    "    \n",
    "    for val_x, val_y in val_loader:\n",
    "        val_x = val_x.to(device)\n",
    "        val_y = val_y.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        \n",
    "        pred_probs = model(val_x) # [B, A, bins]\n",
    "        pred_probs = F.softmax(pred_probs / trans_temp, dim=-1)\n",
    "\n",
    "        co = val_y[:, :, 0] # [B, A]\n",
    "        hi = val_y[:, :, 1]\n",
    "        lo = val_y[:, :, 2]\n",
    "\n",
    "        target_probs = triangular_soft_label(co, lo, hi, bin_centers, triangle_temp)  # [B, A, bins]\n",
    "\n",
    "        loss = wasserstein_loss(pred_probs, target_probs)\n",
    "        \n",
    "        val_loss += loss\n",
    "        \n",
    "        alloc, port_ret, single_returns, leverage = calc_alloc_return(\n",
    "                            pred_probs, co, bin_centers,\n",
    "                            cash_threshold=train_cash_threshold,\n",
    "                            temp=train_temp,\n",
    "                            apply_confidence_mask=False,\n",
    "                            min_prob=train_min_prob,\n",
    "                            allow_leverage=allow_leverage\n",
    "                        )\n",
    "        \n",
    "        returns_buffer.append(port_ret)  # accumulate tensors directly\n",
    "        total_ret += port_ret.sum().item()\n",
    "        sample_count += port_ret.shape[0]\n",
    "\n",
    "    returns_tensor = torch.cat(returns_buffer, dim=0)  # shape [N], retains grad\n",
    "    \n",
    "    sharpe_ratio, max_drawdown, annualized_return, equity_curve = calc_performance_metrics(returns_tensor)\n",
    "                        \n",
    "    avg_val_loss = val_loss / len(val_loader) / in_size\n",
    "            \n",
    "    if (train_step % 1 == 0):\n",
    "        \n",
    "        group = optimizer.param_groups[0]\n",
    "        step = group['step']\n",
    "        momentum_schedule = group['momentum_schedule']\n",
    "        current_momentum = momentum_schedule(step)\n",
    "\n",
    "        print(f\"<========== Training metrics ==========>\")\n",
    "        print(f\"Step              : {train_step+1}/{total_steps}\")\n",
    "        print(f\"LR in microns     : {scheduler.get_last_lr()[0]*10e6:.1f}\")\n",
    "        print(f\"Current Momentum  : {current_momentum:.2f}\")\n",
    "        print()\n",
    "        print(f\"Train Loss        : {avg_train_loss:.4f}\")\n",
    "        print(f\"Validation Loss   : {avg_val_loss:.4f}\")\n",
    "        #print(f\"Std{pred_probs.std(dim=-1).mean():.4f})\n",
    "        print(f\"<========== Quick Validation set Performance ==========>\")\n",
    "        print(f\"Final cumulative return: {equity_curve[-1] - 1:.2%}\")\n",
    "        print(f\"Annualized return: {annualized_return:.2%}\")\n",
    "        print(f\"Sharpe ratio: {sharpe_ratio:.2f}\")\n",
    "        print(f\"Max drawdown: {max_drawdown:.2%}\")\n",
    "        print()\n",
    "\n",
    "torch.save({'model_state_dict': model.state_dict()}, f\"pre_trained.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d3fb3-3cde-457f-84a1-e929559c0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#### single step learning ####\n",
    "##############################\n",
    "\n",
    "cash_threshold = 0.00\n",
    "temp = 0.005\n",
    "min_prob = 0.50\n",
    "\n",
    "allow_leverage = True\n",
    "\n",
    "# Training Parameters\n",
    "lr_single = 1e-4\n",
    "weight_decay_single = 0.0\n",
    "momentum_single = 0.99\n",
    "\n",
    "sgd_opt = ArbitraryMomentumSGD(\n",
    "    model.parameters(),\n",
    "    lr=lr_single,\n",
    "    momentum_schedule=lambda step: momentum_single + 0.0 * torch.tensor(step)  # Cyclic  in [-0.1, 0.9]\n",
    ")\n",
    "\n",
    "# Now first calculate performance and the train\n",
    "\n",
    "returns_buffer = []\n",
    "allocs_buffer = []\n",
    "single_returns_buffer = []\n",
    "leverage_returns_buffer = []\n",
    "total_ret, sample_count = 0, 0\n",
    "\n",
    "val_loss = 0\n",
    "\n",
    "train_iters = 1\n",
    "training_steps = 5\n",
    "\n",
    "train, val, test = split_time_series(data, train_ratio=train_ratio, val_ratio=val_ratio)\n",
    "data_set = test\n",
    "\n",
    "# Use pretrained model and train for a few datapoints before evaluating each datapoint\n",
    "for k in range(data_set.shape[-1] - training_steps - seq_len - 1):\n",
    "\n",
    "    train_ds = TimeSeriesDataset(data_set[:, :, k: k + seq_len + training_steps + 1], \n",
    "                                 seq_len, max_deviation)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Reset to pre trained state for every iteration\n",
    "    model = Transformer(d_model, in_size, value_size, seq_len, bin_centers, num_heads,\n",
    "                        lstm_layers, num_transformer_blocks, dropout=dropout).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(f\"pre_trained.pth\")\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "    data_pair = 0\n",
    "    for train_x, train_y in train_loader:\n",
    "\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "\n",
    "        for s in range(train_iters):\n",
    "\n",
    "            #if s < train_iters -1:\n",
    "                # Generate a random permutation of assets\n",
    "                #perm = torch.randperm(A, device=batch_x.device)\n",
    "                \n",
    "                # Apply same permutation to both tensors along dim=1\n",
    "                #train_x = train_x[:, perm, :, :]\n",
    "                #train_y = train_y[:, perm]\n",
    "            \n",
    "            ###################\n",
    "            ### First train ###\n",
    "            ###################\n",
    "            if data_pair < training_steps - 1:\n",
    "                \n",
    "                model.train()\n",
    "\n",
    "                pred_probs = model(train_x) # [B, A, bins]\n",
    "                pred_probs = F.softmax(pred_probs / trans_temp, dim=-1)\n",
    "\n",
    "                co = train_y[:, :, 0] # [B, A]\n",
    "                hi = train_y[:, :, 1]\n",
    "                lo = train_y[:, :, 2]\n",
    "        \n",
    "                target_probs = triangular_soft_label(co, lo, hi, bin_centers, triangle_temp)  # [B, A, bins]\n",
    "                loss = wasserstein_loss(pred_probs, target_probs)\n",
    "        \n",
    "                # train stock predictor\n",
    "                sgd_opt.zero_grad()\n",
    "            \n",
    "                loss.backward()\n",
    "                sgd_opt.step()\n",
    "\n",
    "        #####################\n",
    "        ### Then evaluate ###\n",
    "        #####################\n",
    "        if data_pair == training_steps - 1:\n",
    "                    \n",
    "            model.eval()\n",
    "\n",
    "            pred_probs = model(train_x) # [B, A, bins]\n",
    "            pred_probs = F.softmax(pred_probs / trans_temp, dim=-1)\n",
    "\n",
    "            co = train_y[:, :, 0] # [B, A]\n",
    "            hi = train_y[:, :, 1]\n",
    "            lo = train_y[:, :, 2]\n",
    "    \n",
    "            target_probs = triangular_soft_label(co, lo, hi, bin_centers, triangle_temp)  # [B, A, bins]\n",
    "            loss = wasserstein_loss(pred_probs, target_probs)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "                    \n",
    "            alloc, port_ret, single_returns, leverage = calc_alloc_return(\n",
    "                                                        pred_probs, co, bin_centers,\n",
    "                                                        cash_threshold=cash_threshold,\n",
    "                                                        temp=temp,\n",
    "                                                        apply_confidence_mask=True,\n",
    "                                                        min_prob=min_prob,\n",
    "                                                        allow_leverage=allow_leverage\n",
    "                                                   )\n",
    "        \n",
    "            single_returns_buffer.append(single_returns)\n",
    "            leverage_returns_buffer.append(leverage)\n",
    "            returns_buffer.append(port_ret)  # accumulate tensors directly\n",
    "            allocs_buffer.append(alloc)\n",
    "            total_ret += port_ret.sum().item()\n",
    "            sample_count += port_ret.shape[0]\n",
    "        \n",
    "        data_pair +=1\n",
    "\n",
    "avg_train_loss = val_loss / (data_set.shape[-1] - training_steps - seq_len - 1) / in_size\n",
    "\n",
    "returns_tensor = torch.cat(returns_buffer, dim=0)  # shape [N], retains grad\n",
    "sharpe_ratio, max_drawdown, annualized_return, equity_curve = calc_performance_metrics(returns_tensor)\n",
    "\n",
    "print(f\"<========== Online Learaning Performance ==========>\")\n",
    "print(f\"Loss                   : {avg_train_loss:.4f}\")\n",
    "print(f\"Final cumulative return: {equity_curve[-1] - 1:.2%}\")\n",
    "print(f\"Annualized return      : {annualized_return:.2%}\")\n",
    "print(f\"Sharpe ratio           : {sharpe_ratio:.2f}\")\n",
    "print(f\"Max drawdown           : {max_drawdown:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856c23e-5061-4af9-beb7-94b4c0706333",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n<========== Final Test Performance ==========>\")\n",
    "print(f\"Final cumulative return: {equity_curve[-1] - 1:.2%}\")\n",
    "print(f\"Buy and Hold return: {buy_and_hold:.2%}\")\n",
    "print(f\"Annualized return: {annualized_return:.2%}\")\n",
    "print(f\"Sharpe ratio: {sharpe_ratio:.2f}\")\n",
    "print(f\"Max drawdown: {max_drawdown:.2%}\")\n",
    "\n",
    "print(f\"\\n<========== S&P 500 Performance ==========>\")\n",
    "print(f\"Final cumulative return: {0.285 * len(equity_curve) / 390:.2%}\")\n",
    "print(f\"Annualized return: 18.9%\")\n",
    "print(f\"Sharpe ratio: 1.40\")\n",
    "print(f\"Max drawdown: -8%\")\n",
    "\n",
    "print()\n",
    "print(f\"Number of samples: {len(equity_curve)}\")\n",
    "\n",
    "print(f\"\\n<========== Bootstrap results ==========>\")\n",
    "results = compute_bootstrap_metrics(returns_tensor, n_bootstrap=1000, ci=0.95)\n",
    "for name, (mean_val, low, high) in results.items():\n",
    "    print(f\"{name.replace('_', ' ').title()}: {mean_val*100:.2f}% \"\n",
    "          f\"[{low*100:.2f}%, {high*100:.2f}%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f9b97-2691-4aba-948e-b1060c318710",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "for batch_x, batch_y in test_loader:\n",
    "            \n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.to(device)\n",
    "\n",
    "    co = batch_y[:, :, 0] # [B, A]\n",
    "    hi = batch_y[:, :, 1]\n",
    "    lo = batch_y[:, :, 2]\n",
    "\n",
    "    pred_probs = model(train_x) # [B, A, bins]\n",
    "    pred_probs = F.softmax(pred_probs / trans_temp, dim=-1)\n",
    "\n",
    "    target_probs = triangular_soft_label(co, lo, hi, test_bin_centers, temp=triangle_temp)  # [B, A, bins]\n",
    "    target_probs = target_probs.detach().cpu().numpy()\n",
    "\n",
    "    single_asset = pred_probs[0, 3, :].detach().cpu().numpy() # [bins]\n",
    "    plt.plot(test_bin_centers.numpy(), single_asset)\n",
    "    plt.ylim(-0.001)\n",
    "\n",
    "    plt.title(\"Real Data Triangular Soft Label Distribution\")\n",
    "    plt.xlabel(\"Bin Centers\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(np.sum(single_asset))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05e198-1096-44cb-9b0f-50e2a02587c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "stock_names = [filename.split(\".\")[0] for filename in stock_data.files]\n",
    "\n",
    "# Assuming all_allocs and stock_data are already defined\n",
    "allocs_tensor = torch.cat(allocs_buffer, dim=0)\n",
    "allocs_tensor = allocs_tensor.detach().cpu().numpy()\n",
    "\n",
    "single_returns_tensor = torch.cat(single_returns_buffer, dim=0)\n",
    "single_returns_tensor = single_returns_tensor.detach().cpu().numpy()\n",
    "\n",
    "leverage_returns_tensor = torch.cat(leverage_returns_buffer, dim=0)\n",
    "leverage_returns_tensor = leverage_returns_tensor.detach().cpu().numpy()\n",
    "\n",
    "#################\n",
    "## Allocations ##\n",
    "#################\n",
    "alloc_fig, alloc_ax = plt.subplots(figsize=(100, 25))  # Large figure\n",
    "\n",
    "# Use make_axes_locatable to attach a smaller colorbar axis\n",
    "divider = make_axes_locatable(alloc_ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)  # Smaller colorbar\n",
    "\n",
    "# Plot heatmap\n",
    "image = alloc_ax.imshow(allocs_tensor.T, origin=\"lower\", vmin=0, aspect=\"auto\")\n",
    "\n",
    "# Colorbar with bigger font\n",
    "cb = alloc_fig.colorbar(image, cax=cax)\n",
    "cb.ax.tick_params(labelsize=50)\n",
    "\n",
    "# Bigger tick labels on y-axis\n",
    "alloc_ax.set_yticks(range(len(stock_names)))\n",
    "alloc_ax.set_yticklabels(stock_names, rotation=0, ha=\"right\", rotation_mode=\"anchor\", fontsize=50)\n",
    "\n",
    "# Bigger tick labels on x-axis\n",
    "alloc_ax.tick_params(axis=\"x\", labelsize=50)\n",
    "\n",
    "# Bigger axis labels if needed\n",
    "alloc_ax.set_xlabel(\"Time Steps\", fontsize=60)\n",
    "alloc_ax.set_ylabel(\"Stocks\", fontsize=60)\n",
    "\n",
    "alloc_ax.grid()\n",
    "\n",
    "#################\n",
    "#### Returns ####\n",
    "#################\n",
    "\n",
    "fig, (ret_ax, lev_ax) = plt.subplots(\n",
    "    nrows=2,\n",
    "    figsize=(100, 50),\n",
    "    gridspec_kw={\"height_ratios\": [1, 1]}\n",
    ")\n",
    "\n",
    "# Use make_axes_locatable to attach a smaller colorbar axis\n",
    "ret_divider = make_axes_locatable(ret_ax)\n",
    "ret_cax = ret_divider.append_axes(\"right\", size=\"2%\", pad=0.1)  # Smaller colorbar\n",
    "\n",
    "# Plot heatmap\n",
    "max_value = np.max(np.abs(single_returns_tensor))\n",
    "image = ret_ax.imshow(\n",
    "    single_returns_tensor.T, origin=\"lower\", vmin=-max_value, vmax=max_value, aspect=\"auto\", cmap=\"bwr\"\n",
    ")\n",
    "\n",
    "# Colorbar with bigger font\n",
    "ret_cb = fig.colorbar(image, cax=ret_cax)\n",
    "ret_cb.ax.tick_params(labelsize=50)\n",
    "\n",
    "# Bigger tick labels on y-axis\n",
    "ret_ax.set_yticks(range(len(stock_names)))\n",
    "ret_ax.set_yticklabels(stock_names, rotation=0, ha=\"right\", rotation_mode=\"anchor\", fontsize=50)\n",
    "\n",
    "ret_ax.set_ylabel(\"Stocks\", fontsize=60)\n",
    "\n",
    "ret_ax.grid()\n",
    "\n",
    "# Use make_axes_locatable to attach a smaller colorbar axis\n",
    "lev_divider = make_axes_locatable(lev_ax)\n",
    "lev_cax = lev_divider.append_axes(\"right\", size=\"2%\", pad=0.1)  # Smaller colorbar\n",
    "\n",
    "#############\n",
    "### Lever ###\n",
    "#############\n",
    "leverage_returns_tensor = np.where(\n",
    "    allocs_tensor > 0.1, leverage_returns_tensor, 0)\n",
    "\n",
    "max_leverage = np.max(np.abs(leverage_returns_tensor))\n",
    "leverage_image = lev_ax.imshow(\n",
    "    leverage_returns_tensor.T, origin=\"lower\", vmin=-max_leverage, vmax=max_leverage, aspect=\"auto\", cmap=\"PiYG\"\n",
    ")\n",
    "\n",
    "# Colorbar with bigger font\n",
    "lev_cb = fig.colorbar(leverage_image, cax=lev_cax)\n",
    "lev_cb.ax.tick_params(labelsize=50)\n",
    "\n",
    "# Bigger tick labels on x-axis\n",
    "lev_ax.tick_params(axis=\"x\", labelsize=50)\n",
    "\n",
    "# Bigger axis labels if needed\n",
    "lev_ax.set_xlabel(\"Time Steps\", fontsize=60)\n",
    "\n",
    "lev_ax.grid()\n",
    "\n",
    "# Bigger tick labels on y-axis\n",
    "lev_ax.set_yticks(range(len(stock_names)))\n",
    "lev_ax.set_yticklabels(stock_names, rotation=0, ha=\"right\", rotation_mode=\"anchor\", fontsize=50)\n",
    "\n",
    "alloc_fig.suptitle(\"Relative allocations at every timestep\", fontsize=80)\n",
    "fig.suptitle(\"Returns of stocks at every timestep\", fontsize=80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3154c5e1-1970-49ac-98a4-f7b1b08ecb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
