{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1039,
   "id": "34300ad0-617f-416d-b249-8d7c6b16ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import StudentT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from collections import defaultdict\n",
    "from random import uniform\n",
    "from tqdm import tqdm\n",
    "import scipy.stats\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "id": "e93dcfe3-eed6-47c1-96eb-2e01c8b9e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatioTemporalCausalAttention(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_assets, num_timesteps):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(input_dim, embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.output_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.num_assets = num_assets\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        # Precompute causal time mask\n",
    "        t = num_timesteps\n",
    "        a = num_assets\n",
    "        time_ids = torch.arange(t).repeat(a)  # [A*T]\n",
    "        mask = time_ids[None, :] <= time_ids[:, None]\n",
    "        self.register_buffer(\"causal_mask\", (~mask).float() * float('-inf'))  # [A*T, A*T]\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, A, T, V = x.shape\n",
    "        x = x.permute(0, 2, 1, 3).reshape(B, A*T, V)  # [B, A*T, V]\n",
    "        x = self.embed(x)\n",
    "    \n",
    "        # Recreate the mask dynamically in case T is variable\n",
    "        time_ids = torch.arange(T, device=x.device).repeat(A)\n",
    "        mask = time_ids[None, :] <= time_ids[:, None]\n",
    "        causal_mask = (~mask).float() * float('-1e9')  # [A*T, A*T]\n",
    "    \n",
    "        attn_out, _ = self.attn(x, x, x, attn_mask=causal_mask)\n",
    "        x_proj = self.output_proj(attn_out)\n",
    "        \n",
    "        return x_proj.reshape(B, T, A, -1).permute(0, 2, 1, 3)  # [B, A, T, E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "796046ce-141d-49e1-bdf0-cca2085ab942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTimescaleLSTM(nn.Module):\n",
    "    def __init__(self, asset_size, h_size, n_layers, batch_size, seq_len,\n",
    "                 pre_heads, time_heads, asset_heads, num_studentT,\n",
    "                 value_size, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.asset_out_size = asset_size\n",
    "        self.value_size = value_size\n",
    "        self.h_size = h_size\n",
    "        self.seq_len = seq_len\n",
    "        self.num_studentT = num_studentT\n",
    "\n",
    "        # === Attention Modules ===\n",
    "        self.spatio_temporal_attn = SpatioTemporalCausalAttention(\n",
    "            input_dim=value_size,\n",
    "            embed_dim=h_size,\n",
    "            num_heads=pre_heads,\n",
    "            num_assets=asset_size,\n",
    "            num_timesteps=seq_len\n",
    "        )\n",
    "\n",
    "        self.temporal_attn = nn.MultiheadAttention(embed_dim=h_size, num_heads=time_heads, batch_first=True)\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim=h_size, num_heads=asset_heads, batch_first=True)\n",
    "\n",
    "        # === LSTM ===\n",
    "        self.lstm = nn.LSTM(\n",
    "            #input_size=asset_size * h_size,\n",
    "            input_size=asset_size * value_size,\n",
    "            hidden_size=h_size,\n",
    "            num_layers=n_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # === Linear Layers ===\n",
    "        self.post_fc = nn.Linear(asset_size * h_size, 4 * asset_size * num_studentT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, A, V, T]\n",
    "        \"\"\"\n",
    "        B, A, V, T = x.shape\n",
    "        H = self.h_size\n",
    "        #x = x.transpose(2, 3)  # -> [B, A, T, V]\n",
    "\n",
    "        # === Spatio-Temporal Attention ===\n",
    "        #x_attn = self.spatio_temporal_attn(x)  # [B, A, T, H]\n",
    "        #x_attn = x_attn.transpose(1, 2)          # [B, T, A, H]\n",
    "        #B, T, A, H = x_attn.shape\n",
    "        #x_flat = x_attn.reshape(B, T, A * H)     # [B, T, A*H]\n",
    "        x = x.transpose(1, 3)\n",
    "        x_flat = x.reshape(B, T, A*V)\n",
    "\n",
    "        # === LSTM ===\n",
    "        lstm_out, _ = self.lstm(x_flat)          # [B, T, H]\n",
    "\n",
    "        # === Temporal Attention with Causal Mask ===\n",
    "        device = lstm_out.device\n",
    "        causal_mask = torch.triu(torch.full((T, T), float('-inf')), diagonal=1).to(device)\n",
    "        temp_out, _ = self.temporal_attn(lstm_out, lstm_out, lstm_out, attn_mask=causal_mask)\n",
    "\n",
    "        # === Cross-Asset Attention ===\n",
    "        final_state = temp_out[:, -1, :]                  # [B, H]\n",
    "        expanded = final_state.unsqueeze(1).repeat(1, A, 1)  # [B, A, H]\n",
    "        asset_out, _ = self.cross_attn(expanded, expanded, expanded)  # [B, A, H]\n",
    "        asset_flat = asset_out.reshape(B, A * H)          # [B, A*H]\n",
    "\n",
    "        final = self.post_fc(asset_flat) # [B, A*5]\n",
    "        final = final.view(B, A, 4, self.num_studentT)\n",
    "\n",
    "        # === Output Parameters ===\n",
    "        # [B, A, K]\n",
    "        mu       = final[:, :, 0, :]\n",
    "        log_sigma = final[:, :, 1, :]\n",
    "        log_nu    = final[:, :, 2, :]\n",
    "        dist_weights = final[:, :, 3, :]\n",
    "\n",
    "        sigma = torch.exp(log_sigma) + 1e-2\n",
    "        nu = torch.exp(log_nu) + 2.0\n",
    "        dist_weights = torch.softmax(dist_weights, dim=-1)\n",
    "\n",
    "        return mu, sigma, nu, dist_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "4174cf13-7f92-4b0e-af0e-d9c935698254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define evaluation points from 0 to 10\\nx = torch.linspace(-1, 1, 1000)  # shape [1000]\\n\\nmu = torch.zeros_like(x) + 0.13\\nsig = torch.zeros_like(x) + 0.35\\nnu = torch.zeros_like(x) + 3.45\\ndist_weights = torch.zeros_like(x) + 3.45\\n\\n# Compute log-PDF and exponentiate\\nlog_pdf = mixture_student_t_logpdf(x, mu, sig, nu, dist_weights)\\npdf = torch.exp(log_pdf)\\n\\n# Numerical integration over [0, 10]\\narea = torch.trapz(pdf, x)\\nprint(\"Integral over [0, 10]:\", area.item())\\n\\n# Plot\\nplt.plot(x, pdf)\\nplt.title(\"PDF on [0, 10]\")\\nplt.grid()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 1042,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mixture_student_t_logpdf(x, mus, sigmas, nus, dist_weights):\n",
    "    \"\"\"\n",
    "    Log-likelihood of Mixture of Student-t Distributions.\n",
    "\n",
    "    Inputs:\n",
    "        x:        [B, A]         target returns\n",
    "        mus:      [B, A, K]      mixture component means\n",
    "        sigmas:   [B, A, K]      std deviations (must be positive)\n",
    "        nus:      [B, A, K]      degrees of freedom (must be > 2)\n",
    "        weights:  [B, A, K]      unnormalized weights\n",
    "\n",
    "    Returns:\n",
    "        log_prob: [B, A]         log-likelihood of each sample\n",
    "    \"\"\"\n",
    "    x = x.unsqueeze(-1).expand_as(mus)  # [B, A, K]\n",
    "    t_dist = StudentT(loc=mus, scale=sigmas, df=nus)\n",
    "    log_pdf = t_dist.log_prob(x)  # [B, A, K]\n",
    "    log_w = F.log_softmax(dist_weights, dim=-1)  # [B, A, K]\n",
    "    return torch.logsumexp(log_pdf + log_w, dim=-1)  # [B, A]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Define evaluation points from 0 to 10\n",
    "x = torch.linspace(-1, 1, 1000)  # shape [1000]\n",
    "\n",
    "mu = torch.zeros_like(x) + 0.13\n",
    "sig = torch.zeros_like(x) + 0.35\n",
    "nu = torch.zeros_like(x) + 3.45\n",
    "dist_weights = torch.zeros_like(x) + 3.45\n",
    "\n",
    "# Compute log-PDF and exponentiate\n",
    "log_pdf = mixture_student_t_logpdf(x, mu, sig, nu, dist_weights)\n",
    "pdf = torch.exp(log_pdf)\n",
    "\n",
    "# Numerical integration over [0, 10]\n",
    "area = torch.trapz(pdf, x)\n",
    "print(\"Integral over [0, 10]:\", area.item())\n",
    "\n",
    "# Plot\n",
    "plt.plot(x, pdf)\n",
    "plt.title(\"PDF on [0, 10]\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "54ba9e53-1761-4162-a899-959a46bcb682",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "def mixture_student_t_loss(mu, sigma, nu, dist_weights, target, deviation=(100., 0.)):\n",
    "\n",
    "    # Dont punish the network for mispredicting unpredictable targets\n",
    "    #target = torch.where(((torch.abs(target) < deviation[0]) & (torch.abs(target) > deviation[1])), target, 0.0)\n",
    "\n",
    "    logp = mixture_student_t_logpdf(target, mu, sigma, nu, dist_weights)\n",
    "    pdf_loss = -logp.mean()\n",
    "        \n",
    "    #sigma_penalty = torch.mean(1.0 / sigma)  # penalize tiny sigma\n",
    "\n",
    "    # Encourage the network to use all student t distributions\n",
    "    weight_entropy = -((1 / dist_weights) * dist_weights.log()).sum(dim=-1).mean()\n",
    "\n",
    "    loss = pdf_loss + weight_entropy * 0.1\n",
    "    \n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "8e01c2b5-9eec-4978-b90b-e7d57966afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset():\n",
    "    def __init__(self, root_dir, seq_len=1024):\n",
    "        self.seq_len = seq_len\n",
    "        self.root_dir = root_dir\n",
    "        self.files = self.get_filenames()\n",
    "        self.data = self.load_data()\n",
    "\n",
    "    def get_filenames(self):\n",
    "        files = os.listdir(self.root_dir)\n",
    "        return files\n",
    "    \n",
    "    def load_data(self):\n",
    "        # Array of dimension [stock name, price category(open, close, high, low, close, volume, date), sequence length]\n",
    "        data = np.zeros((len(self.files), 7, self.seq_len))\n",
    "        \n",
    "        for i, filename in enumerate(self.files):\n",
    "            \n",
    "            with open(self.root_dir + '/' + filename, 'r', encoding=\"utf-8\") as file:\n",
    "                #print(filename)\n",
    "                #head = file.read(1000)\n",
    "                #print(head)  # if this looks binary, it's not a JSON file!\n",
    "                file.seek(0)\n",
    "                content = json.load(file)\n",
    "                time_series = content[\"Time Series (Daily)\"]\n",
    "\n",
    "                df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "                df.columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "                o = df[['open']].to_numpy()\n",
    "                c = df[['close']].to_numpy()\n",
    "                h = df[['high']].to_numpy()\n",
    "                l = df[['low']].to_numpy()\n",
    "                v = df[['volume']].to_numpy()\n",
    "                t = df.index.to_numpy()\n",
    "\n",
    "                # All data is aranged from oldest to newest date\n",
    "                # So we first have to flip the data by [::-1]\n",
    "                data[i, 0, :] = o.flatten()[:self.seq_len][::-1] / o.flatten()[1:self.seq_len + 1][::-1] - 1\n",
    "                data[i, 1, :] = c.flatten()[:self.seq_len][::-1] / c.flatten()[1:self.seq_len + 1][::-1] - 1\n",
    "                data[i, 2, :] = h.flatten()[:self.seq_len][::-1] / h.flatten()[1:self.seq_len + 1][::-1] - 1\n",
    "                data[i, 3, :] = l.flatten()[:self.seq_len][::-1] / l.flatten()[1:self.seq_len + 1][::-1] - 1\n",
    "                data[i, 5, :] = v.flatten()[:self.seq_len][::-1] / v.flatten()[self.seq_len + 1]\n",
    "\n",
    "                # convert date to unix time\n",
    "                dates = t.flatten()[:self.seq_len][::-1]\n",
    "                data[i, 6, :] = dates.astype('datetime64[s]')\n",
    "                data[i, 6, :] = data[i, 6, :].astype('int64')\n",
    "\n",
    "                file.close()\n",
    "\n",
    "            # extra statistics\n",
    "            data[:, 4, :] = data[:, 2, :] - data[:, 3, :] # daily range high - low\n",
    "    \n",
    "        return data\n",
    "\n",
    "    def scale_log(self):\n",
    "        self.data = np.log(1 + self.data)\n",
    "        return 0\n",
    "\n",
    "    def average(self, decay_fac=0.0):\n",
    "        \n",
    "        avg_arr = np.zeros_like(self.data)\n",
    "        \n",
    "        for i in range(self.seq_len):\n",
    "            exp_decay = np.exp(-decay_fac * np.arange(0, self.seq_len - i))\n",
    "            exp_decay = exp_decay[::-1]\n",
    "            exp_decay = np.expand_dims(exp_decay, axis=0)\n",
    "            exp_decay = np.expand_dims(exp_decay, axis=0)\n",
    "            exp_decay = np.repeat(exp_decay, repeats=len(self.files), axis=0)\n",
    "            exp_decay = np.repeat(exp_decay, repeats=5, axis=1)\n",
    "            avg_arr[:,:-1,i] = np.sum(self.data[:,:-1,i:] * exp_decay, axis=-1) / np.sum(exp_decay[:,:,:], axis=-1)\n",
    "        \n",
    "        avg_arr[:,-1,:] = self.data[:,-1,:].copy()\n",
    "\n",
    "        return avg_arr\n",
    "\n",
    "    def recons_absol(self):\n",
    "        # this function only provides a test to reconstruct the original shape of the stock prices\n",
    "        abs_data = np.zeros_like(self.data)\n",
    "        abs_data[:,:,0] = 1.\n",
    "        abs_data[:,-1,:] = self.data[:,-1,:]\n",
    "        # iterate over all timesteps after the first\n",
    "        for j in range(self.data.shape[2] - 1):\n",
    "            abs_data[:, :-1, j+1] = abs_data[:, :-1, j] * (1 + self.data[:, :-1, j])\n",
    "\n",
    "        return abs_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "bcc2e7c7-a241-446d-9836-df1b92c7c743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LMT.json', 'BMW.DE.json', 'FRE.DE.json', 'ENR.DE.json', 'DAI.DE.json', 'SAP.DE.json', 'DHER.DE.json', 'AAPL.json', 'HOT.DE.json', 'RHM.DE.json', 'BAYN.DE.json', 'MUV2.DE.json', 'BAS.DE.json', 'ADS.DE.json', 'DBK.DE.json', 'ALV.DE.json', 'SIE.DE.json', 'DTE.DE.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/lhm9rkfd5mq5nqs778m806v40000gn/T/ipykernel_63232/2628515410.py:86: RuntimeWarning: overflow encountered in multiply\n",
      "  abs_data[:, :-1, j+1] = abs_data[:, :-1, j] * (1 + self.data[:, :-1, j])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#root_dir = \"/Users/silas/work/machine_learning/LSTM/data/data_dump\"\n",
    "root_dir = \"/Users/silas/work/machine_learning/LSTM/data/my_repo\"\n",
    "stock_data = StockDataset(root_dir, seq_len=1124)\n",
    "#stock_data.scale_log()\n",
    "\n",
    "stock_nr = 3\n",
    "\n",
    "print(stock_data.files)\n",
    "#plt.plot(stock_data.data[stock_nr,-1,:], stock_data.data[stock_nr,0,:])\n",
    "\n",
    "abs_data = stock_data.recons_absol()\n",
    "x = abs_data[stock_nr,-1,:]\n",
    "y = np.mean(abs_data[:,0,:], axis=0)\n",
    "\n",
    "y = stock_data.data[stock_nr,0,:]\n",
    "\n",
    "log_y = np.log(1 + y)\n",
    "\n",
    "plt.plot(x, y, color=\"blue\")\n",
    "#plt.plot(x, log_y, color=\"red\")\n",
    "plt.grid()\n",
    "val_cut = x[int(0.7*len(x))]\n",
    "test_cut = x[int(0.85*len(x))]\n",
    "plt.vlines([val_cut, test_cut], -0.3, 0.3, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "baf221e6-1961-432e-8573-4ddd1243f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_len, target_stock_idx, max_deviation=False):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.seq_len = seq_len\n",
    "        self.max_deviation = max_deviation\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[-1] - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[:, :, idx : idx + self.seq_len]\n",
    "        # Mask input data !!! Not Target !!!\n",
    "        if self.max_deviation != False:\n",
    "            x = torch.where(torch.abs(x) > self.max_deviation, 0.0, x)\n",
    "        y = self.data[:, target_stock_idx, idx + self.seq_len]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "3f86ed9d-f7bf-483b-995c-9792f1b2a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series(data, train_ratio=0.7, val_ratio=0.15):\n",
    "    time_steps = data.shape[-1]\n",
    "    #print(f\"Time steps: {time_steps}\")\n",
    "    train_end = int(time_steps * train_ratio)\n",
    "    val_end = int(time_steps * (train_ratio + val_ratio))\n",
    "    return data[:, :, 0:train_end], data[:, :, train_end:val_end], data[:, :, val_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "da0b2f04-c713-41d2-a37c-3881f3bb7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warmup_cosine_scheduler(optimizer, warmup_steps, total_steps, lr_max):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return current_step / warmup_steps\n",
    "        else:\n",
    "            progress = (current_step - warmup_steps) / (total_steps - warmup_steps)\n",
    "            return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "73d3ccc8-335f-4b2a-9256-c9835e0937a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_warmup_steps = 100\n",
    "dummy_total_steps = 1000\n",
    "dummy_lr = np.zeros(dummy_total_steps)\n",
    "dummy_steps = np.arange(0, dummy_total_steps, 1)\n",
    "\n",
    "for step in dummy_steps:\n",
    "    if step < dummy_warmup_steps:\n",
    "        dummy_lr[step] = step / dummy_warmup_steps\n",
    "    else:\n",
    "        progress = (step - dummy_warmup_steps) / (dummy_total_steps - dummy_warmup_steps)\n",
    "        dummy_lr[step] = 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "plt.plot(dummy_steps, dummy_lr)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "772d80f0-0d4f-4cfc-a752-edcb6dae7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm model parameters\n",
    "h_size = 16\n",
    "n_layers = 3\n",
    "num_studentT = 3\n",
    "\n",
    "pre_heads = 2\n",
    "time_heads = 2\n",
    "asset_heads = 2\n",
    "\n",
    "dropout = 0.5\n",
    "seq_len = 16\n",
    "batch_size = 1\n",
    "deviation = (100.00, 0.0) # target deviation in loss function\n",
    "\n",
    "# training lstm model\n",
    "warmup_steps = 20\n",
    "total_steps = 120\n",
    "lr_max=5e-6\n",
    "weight_decay = 1e-6\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "66463370-f7f9-4a92-9aed-d963481a39c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock dimension: (18, 7, 1124)\n",
      "Value size: 5\n"
     ]
    }
   ],
   "source": [
    "in_size = len(stock_data.files) # number of stocks\n",
    "data = stock_data.data[:,:5,:] # Pass only OHLC, not V\n",
    "target_stock_idx = 1 # [open, close, high, low, volume, datetime]\n",
    "\n",
    "print(f\"Stock dimension: {stock_data.data.shape}\")\n",
    "value_size = data_pass.shape[1]\n",
    "print(f\"Value size: {value_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "816cf1fc-e09c-431b-9c04-1ad6d92cb9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: train=(18, 5, 786) val=(18, 5, 169) test=(18, 5, 169)\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "max_deviation = 0.05 # Mask extreme data\n",
    "\n",
    "###############\n",
    "#### Data #####\n",
    "###############\n",
    "train, val, test = split_time_series(train_data, train_ratio=train_ratio, val_ratio=val_ratio)\n",
    "print(f\"Shapes: train={train.shape} val={val.shape} test={test.shape}\")\n",
    "\n",
    "train_ds = TimeSeriesDataset(train, seq_len, target_stock_idx, max_deviation)\n",
    "val_ds = TimeSeriesDataset(val, seq_len, target_stock_idx, max_deviation)\n",
    "test_ds = TimeSeriesDataset(test, seq_len, target_stock_idx, max_deviation)\n",
    "#print(f\"Shapes: train={train.shape} val={val.shape} test={test.shape}\")\n",
    "\n",
    "# (Batch, in_size, seq_len)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "id": "8cac5b04-acd6-4299-b9be-26dabf0ba788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "id": "70043128-d186-4136-a5ed-1fa3cfa45ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTimescaleLSTM(in_size, h_size, n_layers, batch_size, seq_len, pre_heads, \n",
    "                           time_heads, asset_heads, num_studentT, value_size, dropout).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr_max, weight_decay=weight_decay, momentum=momentum)\n",
    "scheduler = get_warmup_cosine_scheduler(optimizer, warmup_steps=warmup_steps, total_steps=total_steps, lr_max=lr_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "id": "a8b64e1b-a8a9-4e93-aacd-c6f480454005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_correct_preds(test_data, mu, sigma, nu, dist_weights, threshold):\n",
    "\n",
    "    sigma = np.where(nu > 2, np.sqrt(nu / (nu-2)) * sigma, 1e10)\n",
    "    \n",
    "    # signal to noise ratio\n",
    "    s_n = np.abs(mu) / sigma\n",
    "\n",
    "    significant_out = np.where(s_n > threshold, np.where(mu > 0, 1, -1), 0.)\n",
    "\n",
    "    samples = np.sum((significant_out * test_data) != 0)\n",
    "    correct_sign = np.sum((significant_out * test_data) > 0.)\n",
    "\n",
    "    return samples, correct_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "id": "77f97ff2-8da7-456c-84b2-26c96453bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alloc_return(\n",
    "    mu, sigma, nu, dist_weights, real_returns,\n",
    "    cash_threshold=0.3,\n",
    "    temp=1.0,\n",
    "    apply_confidence_mask=True,\n",
    "    min_prob=0.1,\n",
    "    max_loss=0.05,\n",
    "    invest_sigmoid_scale=10.0,\n",
    "    allow_short=True\n",
    "):\n",
    "    B, A, K = mu.shape\n",
    "    device = mu.device\n",
    "\n",
    "    # Add 'cash' asset\n",
    "    mu = torch.cat([mu, torch.zeros(B, 1, K, device=device)], dim=1)\n",
    "    sigma = torch.cat([sigma, torch.ones(B, 1, K, device=device)], dim=1)\n",
    "    nu = torch.cat([nu, torch.full((B, 1, K), 10.0, device=device)], dim=1)\n",
    "    dist_weights = torch.cat([dist_weights, torch.full((B, 1, K), 1e-9, device=device)], dim=1)\n",
    "    real_returns = torch.cat([real_returns, torch.zeros(B, 1, device=device)], dim=1)\n",
    "\n",
    "    def mix_pdf(x_grid):\n",
    "        x = x_grid[:, None, None, None]  # [X, 1, 1, 1]\n",
    "        dist = StudentT(loc=mu[None], scale=sigma[None], df=nu[None])\n",
    "        pdf = dist.log_prob(x).exp()\n",
    "        return (dist_weights[None] * pdf).sum(dim=-1)  # [X, B, A+1]\n",
    "\n",
    "    def integrate(x, y):\n",
    "        return torch.trapz(y, x, dim=0)\n",
    "\n",
    "    x_grid = torch.linspace(-10, 10, 10000, device=device)\n",
    "    pdf = mix_pdf(x_grid)\n",
    "    pos_prob = integrate(x_grid, pdf * (x_grid > 0).float()[:, None, None])\n",
    "    exp_gain = integrate(x_grid, pdf * x_grid[:, None, None])\n",
    "\n",
    "    x_loss = torch.linspace(-10, -float(max_loss), 10000, device=device)\n",
    "    pdf_loss = mix_pdf(x_loss)\n",
    "    loss_prob = integrate(x_loss, pdf_loss)\n",
    "\n",
    "    pos_prob[:, -1] = cash_threshold\n",
    "    if apply_confidence_mask:\n",
    "        #min_prob = min_prob.view(-1, 1)\n",
    "        pos_prob *= (pos_prob.abs() > min_prob).float()\n",
    "    #pos_prob *= (loss_prob < max_loss).float()\n",
    "\n",
    "    alloc_raw = F.softmax(pos_prob / temp, dim=-1)\n",
    "    mu_mean = mu.mean(dim=2)\n",
    "    max_sig = pos_prob[:, :-1].max(dim=1, keepdim=True)[0]\n",
    "    invest_ratio = torch.sigmoid((max_sig - cash_threshold) * invest_sigmoid_scale)\n",
    "    allocations = alloc_raw * invest_ratio\n",
    "\n",
    "    returns = torch.where(mu_mean > 0, real_returns, -real_returns) if allow_short else real_returns * (mu_mean > 0).float()\n",
    "    port_ret = (allocations * returns).sum(dim=1)\n",
    "    return allocations, port_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "id": "26955d0c-8565-4984-90d7-7a4658bf64f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step              : 5/120\n",
      "LR in millions    : 12.500\n",
      "Train Loss        : 2.0080\n",
      "Validation Loss   : 2.0078\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 2.63%\n",
      "Annualized return: 4.37%\n",
      "Sharpe ratio: 0.68\n",
      "Max drawdown: -5.52%\n",
      "mu: -0.0019 [-0.0727, 0.0715]\n",
      "sigma: 1.0165 [0.9504, 1.0832]\n",
      "nu: 2.9993 [2.9300, 3.0701]\n",
      "Weights: 0.3333 [0.3053, 0.3496]\n",
      "\n",
      "Step              : 10/120\n",
      "LR in millions    : 25.000\n",
      "Train Loss        : 2.0062\n",
      "Validation Loss   : 2.0059\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: -3.00%\n",
      "Annualized return: -4.89%\n",
      "Sharpe ratio: -0.83\n",
      "Max drawdown: -5.19%\n",
      "mu: -0.0020 [-0.0731, 0.0714]\n",
      "sigma: 1.0146 [0.9496, 1.0816]\n",
      "nu: 2.9995 [2.9309, 3.0690]\n",
      "Weights: 0.3333 [0.3059, 0.3494]\n",
      "\n",
      "Step              : 15/120\n",
      "LR in millions    : 37.500\n",
      "Train Loss        : 2.0031\n",
      "Validation Loss   : 2.0027\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: -2.86%\n",
      "Annualized return: -4.67%\n",
      "Sharpe ratio: -0.80\n",
      "Max drawdown: -5.16%\n",
      "mu: -0.0020 [-0.0739, 0.0714]\n",
      "sigma: 1.0114 [0.9482, 1.0791]\n",
      "nu: 2.9997 [2.9310, 3.0674]\n",
      "Weights: 0.3333 [0.3067, 0.3493]\n",
      "\n",
      "Step              : 20/120\n",
      "LR in millions    : 50.000\n",
      "Train Loss        : 1.9988\n",
      "Validation Loss   : 1.9982\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: -2.18%\n",
      "Annualized return: -3.56%\n",
      "Sharpe ratio: -0.57\n",
      "Max drawdown: -5.00%\n",
      "mu: -0.0021 [-0.0753, 0.0717]\n",
      "sigma: 1.0070 [0.9459, 1.0761]\n",
      "nu: 3.0000 [2.9292, 3.0656]\n",
      "Weights: 0.3333 [0.3078, 0.3492]\n",
      "\n",
      "Step              : 25/120\n",
      "LR in millions    : 49.692\n",
      "Train Loss        : 1.9935\n",
      "Validation Loss   : 1.9929\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: -1.50%\n",
      "Annualized return: -2.46%\n",
      "Sharpe ratio: -0.38\n",
      "Max drawdown: -4.72%\n",
      "mu: -0.0020 [-0.0775, 0.0724]\n",
      "sigma: 1.0017 [0.9428, 1.0732]\n",
      "nu: 3.0003 [2.9243, 3.0645]\n",
      "Weights: 0.3333 [0.3089, 0.3491]\n",
      "\n",
      "Step              : 30/120\n",
      "LR in millions    : 48.776\n",
      "Train Loss        : 1.9880\n",
      "Validation Loss   : 1.9874\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: -0.78%\n",
      "Annualized return: -1.28%\n",
      "Sharpe ratio: -0.18\n",
      "Max drawdown: -4.45%\n",
      "mu: -0.0020 [-0.0803, 0.0735]\n",
      "sigma: 0.9962 [0.9351, 1.0707]\n",
      "nu: 3.0005 [2.9184, 3.0685]\n",
      "Weights: 0.3333 [0.3098, 0.3491]\n",
      "\n",
      "Step              : 35/120\n",
      "LR in millions    : 47.275\n",
      "Train Loss        : 1.9823\n",
      "Validation Loss   : 1.9816\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: -0.01%\n",
      "Annualized return: -0.01%\n",
      "Sharpe ratio: 0.03\n",
      "Max drawdown: -4.17%\n",
      "mu: -0.0018 [-0.0837, 0.0750]\n",
      "sigma: 0.9905 [0.9232, 1.0687]\n",
      "nu: 3.0007 [2.9123, 3.0734]\n",
      "Weights: 0.3333 [0.3106, 0.3490]\n",
      "\n",
      "Step              : 40/120\n",
      "LR in millions    : 45.225\n",
      "Train Loss        : 1.9761\n",
      "Validation Loss   : 1.9754\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 1.21%\n",
      "Annualized return: 2.00%\n",
      "Sharpe ratio: 0.35\n",
      "Max drawdown: -4.17%\n",
      "mu: -0.0017 [-0.0876, 0.0769]\n",
      "sigma: 0.9843 [0.9105, 1.0669]\n",
      "nu: 3.0008 [2.9057, 3.0791]\n",
      "Weights: 0.3333 [0.3113, 0.3489]\n",
      "\n",
      "Step              : 45/120\n",
      "LR in millions    : 42.678\n",
      "Train Loss        : 1.9695\n",
      "Validation Loss   : 1.9687\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 2.06%\n",
      "Annualized return: 3.41%\n",
      "Sharpe ratio: 0.57\n",
      "Max drawdown: -4.00%\n",
      "mu: -0.0015 [-0.0921, 0.0794]\n",
      "sigma: 0.9777 [0.8971, 1.0652]\n",
      "nu: 3.0009 [2.8989, 3.0855]\n",
      "Weights: 0.3333 [0.3120, 0.3488]\n",
      "\n",
      "Step              : 50/120\n",
      "LR in millions    : 39.695\n",
      "Train Loss        : 1.9623\n",
      "Validation Loss   : 1.9615\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 2.92%\n",
      "Annualized return: 4.85%\n",
      "Sharpe ratio: 0.77\n",
      "Max drawdown: -3.83%\n",
      "mu: -0.0013 [-0.0970, 0.0840]\n",
      "sigma: 0.9706 [0.8829, 1.0635]\n",
      "nu: 3.0010 [2.8918, 3.0925]\n",
      "Weights: 0.3333 [0.3126, 0.3487]\n",
      "\n",
      "Step              : 55/120\n",
      "LR in millions    : 36.350\n",
      "Train Loss        : 1.9546\n",
      "Validation Loss   : 1.9537\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 3.78%\n",
      "Annualized return: 6.30%\n",
      "Sharpe ratio: 0.95\n",
      "Max drawdown: -3.63%\n",
      "mu: -0.0011 [-0.1022, 0.0889]\n",
      "sigma: 0.9631 [0.8682, 1.0616]\n",
      "nu: 3.0011 [2.8845, 3.1000]\n",
      "Weights: 0.3333 [0.3132, 0.3493]\n",
      "\n",
      "Step              : 60/120\n",
      "LR in millions    : 32.725\n",
      "Train Loss        : 1.9465\n",
      "Validation Loss   : 1.9455\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 5.06%\n",
      "Annualized return: 8.47%\n",
      "Sharpe ratio: 1.14\n",
      "Max drawdown: -3.81%\n",
      "mu: -0.0009 [-0.1076, 0.0941]\n",
      "sigma: 0.9551 [0.8532, 1.0595]\n",
      "nu: 3.0012 [2.8771, 3.1078]\n",
      "Weights: 0.3333 [0.3138, 0.3511]\n",
      "\n",
      "Step              : 65/120\n",
      "LR in millions    : 28.911\n",
      "Train Loss        : 1.9380\n",
      "Validation Loss   : 1.9370\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 6.63%\n",
      "Annualized return: 11.16%\n",
      "Sharpe ratio: 1.36\n",
      "Max drawdown: -4.16%\n",
      "mu: -0.0006 [-0.1130, 0.0992]\n",
      "sigma: 0.9469 [0.8381, 1.0572]\n",
      "nu: 3.0013 [2.8698, 3.1157]\n",
      "Weights: 0.3333 [0.3144, 0.3529]\n",
      "\n",
      "Step              : 70/120\n",
      "LR in millions    : 25.000\n",
      "Train Loss        : 1.9294\n",
      "Validation Loss   : 1.9284\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 7.40%\n",
      "Annualized return: 12.48%\n",
      "Sharpe ratio: 1.46\n",
      "Max drawdown: -4.20%\n",
      "mu: -0.0004 [-0.1182, 0.1042]\n",
      "sigma: 0.9387 [0.8233, 1.0546]\n",
      "nu: 3.0015 [2.8629, 3.1234]\n",
      "Weights: 0.3333 [0.3142, 0.3545]\n",
      "\n",
      "Step              : 75/120\n",
      "LR in millions    : 21.089\n",
      "Train Loss        : 1.9209\n",
      "Validation Loss   : 1.9200\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 8.10%\n",
      "Annualized return: 13.69%\n",
      "Sharpe ratio: 1.55\n",
      "Max drawdown: -4.40%\n",
      "mu: -0.0002 [-0.1230, 0.1088]\n",
      "sigma: 0.9307 [0.8094, 1.0519]\n",
      "nu: 3.0016 [2.8565, 3.1307]\n",
      "Weights: 0.3333 [0.3133, 0.3559]\n",
      "\n",
      "Step              : 80/120\n",
      "LR in millions    : 17.275\n",
      "Train Loss        : 1.9130\n",
      "Validation Loss   : 1.9121\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 8.72%\n",
      "Annualized return: 14.77%\n",
      "Sharpe ratio: 1.62\n",
      "Max drawdown: -4.58%\n",
      "mu: -0.0001 [-0.1273, 0.1129]\n",
      "sigma: 0.9234 [0.7968, 1.0492]\n",
      "nu: 3.0017 [2.8507, 3.1373]\n",
      "Weights: 0.3333 [0.3126, 0.3572]\n",
      "\n",
      "Step              : 85/120\n",
      "LR in millions    : 13.650\n",
      "Train Loss        : 1.9059\n",
      "Validation Loss   : 1.9051\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 9.78%\n",
      "Annualized return: 16.61%\n",
      "Sharpe ratio: 1.71\n",
      "Max drawdown: -5.04%\n",
      "mu: 0.0001 [-0.1309, 0.1164]\n",
      "sigma: 0.9168 [0.7859, 1.0466]\n",
      "nu: 3.0019 [2.8458, 3.1431]\n",
      "Weights: 0.3333 [0.3119, 0.3582]\n",
      "\n",
      "Step              : 90/120\n",
      "LR in millions    : 10.305\n",
      "Train Loss        : 1.8999\n",
      "Validation Loss   : 1.8992\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 10.20%\n",
      "Annualized return: 17.34%\n",
      "Sharpe ratio: 1.75\n",
      "Max drawdown: -5.15%\n",
      "mu: 0.0002 [-0.1338, 0.1193]\n",
      "sigma: 0.9114 [0.7769, 1.0444]\n",
      "nu: 3.0020 [2.8418, 3.1478]\n",
      "Weights: 0.3333 [0.3114, 0.3591]\n",
      "\n",
      "Step              : 95/120\n",
      "LR in millions    : 7.322\n",
      "Train Loss        : 1.8951\n",
      "Validation Loss   : 1.8945\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 10.52%\n",
      "Annualized return: 17.90%\n",
      "Sharpe ratio: 1.78\n",
      "Max drawdown: -5.23%\n",
      "mu: 0.0003 [-0.1361, 0.1215]\n",
      "sigma: 0.9071 [0.7699, 1.0429]\n",
      "nu: 3.0020 [2.8387, 3.1515]\n",
      "Weights: 0.3333 [0.3111, 0.3597]\n",
      "\n",
      "Step              : 100/120\n",
      "LR in millions    : 4.775\n",
      "Train Loss        : 1.8916\n",
      "Validation Loss   : 1.8912\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 10.75%\n",
      "Annualized return: 18.31%\n",
      "Sharpe ratio: 1.80\n",
      "Max drawdown: -5.29%\n",
      "mu: 0.0004 [-0.1376, 0.1230]\n",
      "sigma: 0.9040 [0.7650, 1.0420]\n",
      "nu: 3.0021 [2.8365, 3.1541]\n",
      "Weights: 0.3333 [0.3108, 0.3601]\n",
      "\n",
      "Step              : 105/120\n",
      "LR in millions    : 2.725\n",
      "Train Loss        : 1.8893\n",
      "Validation Loss   : 1.8890\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 10.90%\n",
      "Annualized return: 18.58%\n",
      "Sharpe ratio: 1.81\n",
      "Max drawdown: -5.33%\n",
      "mu: 0.0004 [-0.1386, 0.1240]\n",
      "sigma: 0.9020 [0.7618, 1.0415]\n",
      "nu: 3.0021 [2.8352, 3.1557]\n",
      "Weights: 0.3333 [0.3106, 0.3604]\n",
      "\n",
      "Step              : 110/120\n",
      "LR in millions    : 1.224\n",
      "Train Loss        : 1.8881\n",
      "Validation Loss   : 1.8879\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 10.99%\n",
      "Annualized return: 18.73%\n",
      "Sharpe ratio: 1.82\n",
      "Max drawdown: -5.35%\n",
      "mu: 0.0004 [-0.1392, 0.1246]\n",
      "sigma: 0.9010 [0.7601, 1.0412]\n",
      "nu: 3.0021 [2.8344, 3.1566]\n",
      "Weights: 0.3333 [0.3105, 0.3605]\n",
      "\n",
      "Step              : 115/120\n",
      "LR in millions    : 0.308\n",
      "Train Loss        : 1.8876\n",
      "Validation Loss   : 1.8874\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 11.02%\n",
      "Annualized return: 18.79%\n",
      "Sharpe ratio: 1.82\n",
      "Max drawdown: -5.36%\n",
      "mu: 0.0005 [-0.1394, 0.1248]\n",
      "sigma: 0.9006 [0.7595, 1.0410]\n",
      "nu: 3.0021 [2.8341, 3.1570]\n",
      "Weights: 0.3333 [0.3105, 0.3606]\n",
      "\n",
      "Step              : 120/120\n",
      "LR in millions    : 0.000\n",
      "Train Loss        : 1.8875\n",
      "Validation Loss   : 1.8874\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 11.02%\n",
      "Annualized return: 18.80%\n",
      "Sharpe ratio: 1.82\n",
      "Max drawdown: -5.36%\n",
      "mu: 0.0005 [-0.1395, 0.1248]\n",
      "sigma: 0.9005 [0.7594, 1.0410]\n",
      "nu: 3.0022 [2.8341, 3.1570]\n",
      "Weights: 0.3333 [0.3105, 0.3606]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_cash_threshold = 0.05\n",
    "train_temp = 0.01\n",
    "train_min_prob = 0.01\n",
    "train_max_loss = 0.05\n",
    "train_invest_sigmoid_scale = 5\n",
    "\n",
    "# Train LSTM model\n",
    "for step in range(total_steps):\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # train stock predictor\n",
    "        optimizer.zero_grad()\n",
    "        mu, sigma, nu, dist_weights = model(batch_x)\n",
    "        loss = mixture_student_t_loss(mu, sigma, nu, dist_weights, batch_y, deviation)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    if (step % 5 == 4):\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        all_returns = []\n",
    "        total_ret, sample_count = 0, 0\n",
    "    \n",
    "        for val_x, val_y in val_loader:\n",
    "            val_x = val_x.to(device)\n",
    "            val_y = val_y.to(device)\n",
    "    \n",
    "            mu, sigma, nu, dist_weights = model(val_x)\n",
    "            loss = mixture_student_t_loss(mu, sigma, nu, dist_weights, val_y, deviation)\n",
    "    \n",
    "            val_loss += loss.item()\n",
    "    \n",
    "            # === Apply current threshold to get allocation and returns ===\n",
    "            alloc, port_ret = calc_alloc_return(\n",
    "                mu, sigma, nu, dist_weights, val_y,\n",
    "                cash_threshold=train_cash_threshold,\n",
    "                temp=train_temp,\n",
    "                apply_confidence_mask=True,\n",
    "                min_prob=train_min_prob,\n",
    "                max_loss=train_max_loss,\n",
    "                invest_sigmoid_scale=train_invest_sigmoid_scale,\n",
    "                allow_short=True\n",
    "            )\n",
    "        \n",
    "            total_ret += port_ret.sum().item()\n",
    "            sample_count += port_ret.shape[0]\n",
    "        \n",
    "            all_returns.extend(port_ret.detach().cpu().numpy().flatten())\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"Weights: \", dist_weights)\n",
    "        print(\"mu: \", mu)\n",
    "        print(\"sigma: \", sigma)\n",
    "        print(\"nu: \", nu)\n",
    "        \"\"\"\n",
    "            \n",
    "        avg_daily_ret = total_ret / sample_count\n",
    "        annual_ret = ((avg_daily_ret + 1)**252 - 1) * 100  # Trading year  252 days\n",
    "    \n",
    "        # Convert to numpy array\n",
    "        all_returns = np.array(all_returns)  # shape: [n_days]\n",
    "        \n",
    "        # Cumulative equity (compound growth)\n",
    "        equity_curve = np.cumprod(1 + all_returns)\n",
    "        \n",
    "        # Annualized return\n",
    "        annualized_return = (equity_curve[-1]) ** (252 / len(equity_curve)) - 1\n",
    "        \n",
    "        # Sharpe ratio (assume 0% risk-free rate)\n",
    "        sharpe_ratio = np.mean(all_returns) / (np.std(all_returns) + 1e-8) * np.sqrt(252)\n",
    "        \n",
    "        # Max drawdown\n",
    "        rolling_max = np.maximum.accumulate(equity_curve)\n",
    "        drawdowns = (equity_curve - rolling_max) / rolling_max\n",
    "        max_drawdown = drawdowns.min()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"<========== Training metrics ==========>\")\n",
    "        print(f\"Step              : {step+1}/{total_steps}\")\n",
    "        print(f\"LR in millions    : {scheduler.get_last_lr()[0]*10e6:.3f}\")\n",
    "        print(f\"Train Loss        : {avg_train_loss:.4f}\")\n",
    "        print(f\"Validation Loss   : {avg_val_loss:.4f}\")\n",
    "        print(f\"<========== Quick Validation set Performance ==========>\")\n",
    "        print(f\"Final cumulative return: {equity_curve[-1] - 1:.2%}\")\n",
    "        print(f\"Annualized return: {annualized_return:.2%}\")\n",
    "        print(f\"Sharpe ratio: {sharpe_ratio:.2f}\")\n",
    "        print(f\"Max drawdown: {max_drawdown:.2%}\")\n",
    "        print(f\"mu: {mu.mean():.4f} [{mu.min():.4f}, {mu.max():.4f}]\")\n",
    "        print(f\"sigma: {sigma.mean():.4f} [{sigma.min():.4f}, {sigma.max():.4f}]\")\n",
    "        print(f\"nu: {nu.mean():.4f} [{nu.min():.4f}, {nu.max():.4f}]\")\n",
    "        print(f\"Weights: {dist_weights.mean():.4f} [{dist_weights.min():.4f}, {dist_weights.max():.4f}]\")\n",
    "        #print(f\"Weights: {dist_weights.item():.2f}\")\n",
    "        #print(f\"Significant points: {samples}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "id": "1d5d3fb3-3cde-457f-84a1-e929559c0eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<========== Online Learaning Performance ==========>\n",
      "Loss                   : 1.8848\n",
      "Final cumulative return: 8.20%\n",
      "Annualized return: 13.87%\n",
      "Sharpe ratio: 0.97\n",
      "Max drawdown: -14.25%\n",
      "mu: 0.0006 [-0.1422, 0.1282]\n",
      "sigma: 0.8966 [0.7526, 1.0408]\n",
      "nu: 3.0022 [2.8308, 3.1611]\n",
      "Weights: 0.3333 [0.3100, 0.3615]\n"
     ]
    }
   ],
   "source": [
    "# Now train the model after evaluating step by step\n",
    "lr = 5e-6\n",
    "weight_decay = 0.0 #1e-6\n",
    "momentum = 0.9\n",
    "\n",
    "all_returns = []\n",
    "total_ret, sample_count = 0, 0\n",
    "\n",
    "train_loss = 0\n",
    "\n",
    "# Adapt optimizer parameters\n",
    "optimizer.param_groups[0]['lr'] = lr\n",
    "optimizer.param_groups[0]['weight_decay'] = weight_decay\n",
    "optimizer.param_groups[0]['momentum'] = momentum\n",
    "\n",
    "for batch_x, batch_y in test_loader:\n",
    "\n",
    "    ######################\n",
    "    ### first evaluate ###\n",
    "    ######################\n",
    "    model.eval()\n",
    "\n",
    "    mu, sigma, nu, dist_weights = model(batch_x)\n",
    "\n",
    "    alloc, port_ret = calc_alloc_return(\n",
    "            mu, sigma, nu, dist_weights, batch_y,\n",
    "            cash_threshold=train_cash_threshold,\n",
    "            temp=train_temp,\n",
    "            apply_confidence_mask=True,\n",
    "            min_prob=train_min_prob,\n",
    "            max_loss=train_max_loss,\n",
    "            invest_sigmoid_scale=train_invest_sigmoid_scale,\n",
    "            allow_short=True\n",
    "        )\n",
    "\n",
    "    total_ret += port_ret.sum().item()\n",
    "    sample_count += port_ret.shape[0]\n",
    "    \n",
    "    all_returns.extend(port_ret.detach().cpu().numpy().flatten())\n",
    "\n",
    "    ##################\n",
    "    ### Then train ###\n",
    "    ##################\n",
    "    model.train()\n",
    "\n",
    "    batch_x = batch_x.to(device)\n",
    "    batch_y = batch_y.to(device)\n",
    "\n",
    "    # train stock predictor\n",
    "    optimizer.zero_grad()\n",
    "    mu, sigma, nu, dist_weights = model(batch_x)\n",
    "    loss = mixture_student_t_loss(mu, sigma, nu, dist_weights, batch_y, deviation)\n",
    "\n",
    "    train_loss += loss.item()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "avg_train_loss = train_loss / len(val_loader)\n",
    "\n",
    "# Convert to numpy array\n",
    "all_returns = np.array(all_returns)  # shape: [n_days]\n",
    "\n",
    "# Cumulative equity (compound growth)\n",
    "equity_curve = np.cumprod(1 + all_returns)\n",
    "\n",
    "# Annualized return\n",
    "annualized_return = (equity_curve[-1]) ** (252 / len(equity_curve)) - 1\n",
    "\n",
    "# Sharpe ratio (assume 0% risk-free rate)\n",
    "sharpe_ratio = np.mean(all_returns) / (np.std(all_returns) + 1e-8) * np.sqrt(252)\n",
    "\n",
    "# Max drawdown\n",
    "rolling_max = np.maximum.accumulate(equity_curve)\n",
    "drawdowns = (equity_curve - rolling_max) / rolling_max\n",
    "max_drawdown = drawdowns.min()\n",
    "\n",
    "print(f\"<========== Online Learaning Performance ==========>\")\n",
    "print(f\"Loss                   : {avg_train_loss:.4f}\")\n",
    "print(f\"Final cumulative return: {equity_curve[-1] - 1:.2%}\")\n",
    "print(f\"Annualized return: {annualized_return:.2%}\")\n",
    "print(f\"Sharpe ratio: {sharpe_ratio:.2f}\")\n",
    "print(f\"Max drawdown: {max_drawdown:.2%}\")\n",
    "print(f\"mu: {mu.mean():.4f} [{mu.min():.4f}, {mu.max():.4f}]\")\n",
    "print(f\"sigma: {sigma.mean():.4f} [{sigma.min():.4f}, {sigma.max():.4f}]\")\n",
    "print(f\"nu: {nu.mean():.4f} [{nu.min():.4f}, {nu.max():.4f}]\")\n",
    "print(f\"Weights: {dist_weights.mean():.4f} [{dist_weights.min():.4f}, {dist_weights.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "id": "b9bd9057-bc5e-48cf-8d71-f47d359d89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance_metrics(returns, n_bootstrap=1000, ci=0.95):\n",
    "    \"\"\"\n",
    "    Computes metrics and confidence intervals via bootstrapping.\n",
    "    Args:\n",
    "        returns: array-like, daily returns\n",
    "        n_bootstrap: number of resampling iterations\n",
    "        ci: confidence level (default: 95%)\n",
    "    Returns:\n",
    "        Dict of metric -> (mean, lower_ci, upper_ci)\n",
    "    \"\"\"\n",
    "    returns = np.array(returns)\n",
    "    alpha = 1 - ci\n",
    "    metrics = {\n",
    "        'daily_return': [],\n",
    "        'cumulative_return': [],\n",
    "        'annualized_return': [],\n",
    "        'sharpe_ratio': [],\n",
    "        'max_drawdown': []\n",
    "    }\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(returns, size=len(returns), replace=True)\n",
    "\n",
    "        # === Metrics ===\n",
    "        mean_r = np.mean(sample)\n",
    "        std_r = np.std(sample)\n",
    "        sharpe = mean_r / (std_r + 1e-8) * np.sqrt(252)\n",
    "\n",
    "        # Cumulative equity curve\n",
    "        equity = np.cumprod(1 + sample)\n",
    "        cum_return = equity[-1] - 1\n",
    "        annual_ret = (equity[-1])**(252 / len(sample)) - 1\n",
    "\n",
    "        # Drawdown\n",
    "        peak = np.maximum.accumulate(equity)\n",
    "        dd = (equity - peak) / peak\n",
    "        max_dd = dd.min()\n",
    "\n",
    "        # Store\n",
    "        metrics['daily_return'].append(mean_r)\n",
    "        metrics['cumulative_return'].append(cum_return)\n",
    "        metrics['annualized_return'].append(annual_ret)\n",
    "        metrics['sharpe_ratio'].append(sharpe)\n",
    "        metrics['max_drawdown'].append(max_dd)\n",
    "\n",
    "    # Compute CI bounds\n",
    "    def summarize(metric_values):\n",
    "        mean_val = np.mean(metric_values)\n",
    "        lower = np.percentile(metric_values, 100 * alpha / 2)\n",
    "        upper = np.percentile(metric_values, 100 * (1 - alpha / 2))\n",
    "        return mean_val, lower, upper\n",
    "\n",
    "    return {k: summarize(v) for k, v in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "db6b4d55-e716-43e0-ae82-3f8b4ec3d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training allocation model\n",
    "a_warmup_steps = 20\n",
    "a_total_steps = 100\n",
    "a_lr_max=5e-6\n",
    "a_weight_decay = 0\n",
    "\n",
    "# Model parameters\n",
    "hidden_dim = 128\n",
    "embed_dim = 256\n",
    "proj_dim = 128\n",
    "dropout = 0.3\n",
    "\n",
    "# loss parameters\n",
    "cash_penalty_factor = 0.0\n",
    "diversity_penalty_factor = 0.0\n",
    "entropy_coeff = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "id": "1d55ed30-2563-4454-9d53-bf2ee84c36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class allocationModel(nn.Module):\n",
    "    def __init__(self, in_size, num_studentt, hidden_dim, embed_dim, proj_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_size = in_size\n",
    "        self.input_dim = 4 * in_size * num_studentt\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.proj_dim = proj_dim\n",
    "        self.pre_layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(self.hidden_dim, self.embed_dim)\n",
    "        )\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=self.embed_dim, num_heads=4, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.post_layers = nn.Sequential(\n",
    "            nn.Linear(self.embed_dim, self.proj_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(self.proj_dim, in_size + 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, A * 4 * num_studentt]\n",
    "        x = self.pre_layers(x)   # -> [B, A, 32]\n",
    "        attn_out, _ = self.attn(x, x, x)  # self-attention\n",
    "        attn_out = nn.LayerNorm(attn_out.shape[-1])(attn_out)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        out = self.post_layers(attn_out)  # -> [B, A, in_size + 1]\n",
    "        out = torch.softmax(out / 0.01, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "id": "b6079f4a-979a-49e6-a34c-67d72b6e4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingSharpeLoss:\n",
    "    def __init__(self, window_size=100, eps=1e-6, cash_penalty=0.0, diversity_penalty=0.0, entropy_coeff=0.0):\n",
    "        self.window_size = window_size\n",
    "        self.returns = []  # buffer\n",
    "        self.eps = eps\n",
    "        self.cash_penalty = cash_penalty\n",
    "        self.diversity_penalty = diversity_penalty\n",
    "\n",
    "    def __call__(self, weights, target):\n",
    "        # Compute portfolio return\n",
    "        port_return = (weights[:, :-1] * target).sum().item()  # scalar\n",
    "\n",
    "        self.returns.append(port_return)\n",
    "        if len(self.returns) > self.window_size:\n",
    "            self.returns.pop(0)\n",
    "\n",
    "        if len(self.returns) < 2:\n",
    "            # not enough data to compute Sharpe\n",
    "            sharpe = 0.0\n",
    "        else:\n",
    "            r = torch.tensor(self.returns)\n",
    "            sharpe = r.mean() / (r.std(unbiased=False) + self.eps)\n",
    "\n",
    "        # Penalties\n",
    "        cash_pen = weights[:, -1].mean() * self.cash_penalty\n",
    "        diversity_pen = (weights[:, :-1] ** 2).sum().mean() * self.diversity_penalty\n",
    "        entropy = -torch.sum(weights * torch.log(weights + 1e-8), dim=1).mean()\n",
    "\n",
    "        return -sharpe -entropy_coeff * entropy + cash_pen + diversity_pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "199c77ab-2513-4002-b47c-088085fa39b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "allocation_model = allocationModel(in_size, num_studentT, hidden_dim, embed_dim, proj_dim, dropout)\n",
    "allocation_optimizer = torch.optim.Adam(allocation_model.parameters(), lr=a_lr_max, weight_decay=a_weight_decay)\n",
    "allocation_scheduler = get_warmup_cosine_scheduler(allocation_optimizer, warmup_steps=a_warmup_steps, total_steps=a_total_steps, lr_max=a_lr_max)\n",
    "allocation_loss = RollingSharpeLoss(window_size=20, eps=1e-6, cash_penalty=cash_penalty_factor, diversity_penalty=diversity_penalty_factor, entropy_coeff=entropy_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "68d28e84-9de1-47da-a510-3758418f27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    model.eval()\n",
    "    for a_step in range(a_total_steps):\n",
    "        \n",
    "        # Train model\n",
    "        allocation_model.train()\n",
    "    \n",
    "        val_loss = 0\n",
    "        for x_val, y_val in train_loader:\n",
    "            \n",
    "            mu, sigma, nu, weights = model(x_val) # Each [B, A, K]\n",
    "            B, A, K = mu.shape\n",
    "            x = torch.cat([mu, sigma, nu, weights], dim=1) # [B, A * 4, K]\n",
    "            x = x.reshape(B, A * 4 * K)\n",
    "            \n",
    "            output = allocation_model(x)\n",
    "            loss = allocation_loss(output, y_val)\n",
    "    \n",
    "            loss.backward()\n",
    "            allocation_optimizer.step()\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        allocation_scheduler.step()\n",
    "    \n",
    "        # Test performance\n",
    "        allocation_model.eval()\n",
    "    \n",
    "        returns = 0\n",
    "        test_loss = 0\n",
    "        for x_test, y_test in val_loader:\n",
    "    \n",
    "            mu, sigma, nu, weights = model(x_test) # Each [B, A, K]\n",
    "            B, A, K = mu.shape\n",
    "            x = torch.cat([mu, sigma, nu, weights], dim=1) # [B, A * 4, K]\n",
    "            x = x.reshape(B, A * 4 * K)\n",
    "            \n",
    "            output = allocation_model(x)\n",
    "            loss = allocation_loss(output, y_test)\n",
    "    \n",
    "            test_loss += loss.item()\n",
    "    \n",
    "            returns += (output[:, :-1] * y_test).sum()\n",
    "        avg_returns = returns / len(test_loader)\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "    \n",
    "        if (a_step % 10 == 9):\n",
    "            print(f\"Step              : {a_step+1}/{a_total_steps}\")\n",
    "            print(f\"LR in millions    : {allocation_scheduler.get_last_lr()[0]*10e6:.3f}\")\n",
    "            print(f\"Validation loss   : {avg_val_loss:.5f}\")\n",
    "            print(f\"Test loss         : {avg_test_loss:.5f}\")\n",
    "            print(f\"Average Day return: {avg_returns * 100:.2}%\")\n",
    "            print(output)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "185b0edb-33f0-4731-a7be-1acd8d02c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "####### Analyze ########\n",
    "########################\n",
    "\n",
    "def sample_random_params():\n",
    "    return {\n",
    "        \"cash_threshold\": uniform(0.0, 0.05),\n",
    "        \"temp\": uniform(0.001, 0.1),\n",
    "        \"min_prob\": uniform(0.0, 1.0),\n",
    "        \"max_loss\": uniform(0.0, 0.1),\n",
    "        \"invest_sigmoid_scale\": uniform(1.0, 20.0)\n",
    "    }\n",
    "\n",
    "def evaluate_config(model, val_loader, config):\n",
    "    all_returns = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_x, val_y in val_loader:\n",
    "            val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "            mu, sigma, nu, dist_weights = model(val_x)\n",
    "\n",
    "            _, port_ret = calc_alloc_return(\n",
    "                mu, sigma, nu, dist_weights, val_y,\n",
    "                cash_threshold=config['cash_threshold'],\n",
    "                temp=config['temp'],\n",
    "                apply_confidence_mask=True,\n",
    "                min_prob=config['min_prob'],\n",
    "                max_loss=config['max_loss'],\n",
    "                invest_sigmoid_scale=config['invest_sigmoid_scale'],\n",
    "                allow_short=True\n",
    "            )\n",
    "\n",
    "            returns = port_ret.detach().cpu().numpy().flatten()\n",
    "            all_returns.extend(returns)\n",
    "\n",
    "    r = np.array(all_returns)\n",
    "    if len(r) < 10:  # not enough points for reliable metrics\n",
    "        return None\n",
    "\n",
    "    # Metrics\n",
    "    equity = np.cumprod(1 + r)\n",
    "    cumulative_return = equity[-1] - 1\n",
    "    annualized = (equity[-1])**(252 / len(r)) - 1\n",
    "    sharpe = np.mean(r) / (np.std(r) + 1e-8) * np.sqrt(252)\n",
    "    max_dd = (equity - np.maximum.accumulate(equity)) / np.maximum.accumulate(equity)\n",
    "    drawdown = max_dd.min()\n",
    "\n",
    "    return {\n",
    "        'sharpe': sharpe,\n",
    "        'annualized_return': annualized,\n",
    "        'cumulative_return': cumulative_return,\n",
    "        'max_drawdown': drawdown,\n",
    "        'samples': len(r),\n",
    "        'combined': 0.5 * sharpe + 2 * annualized - 1 * abs(drawdown)\n",
    "    }\n",
    "\n",
    "if 0:\n",
    "    n_trials = 500\n",
    "    results = []\n",
    "    \n",
    "    for _ in tqdm(range(n_trials)):\n",
    "        params = sample_random_params()\n",
    "        metrics = evaluate_config(model, val_loader, params)\n",
    "        if metrics:\n",
    "            results.append({\n",
    "                **params,\n",
    "                **metrics\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "3130dd32-2bfc-4515-b90a-c20023ccbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    \"\"\"\n",
    "    'sharpe'\n",
    "    'annualized_return'\n",
    "    'cumulative_return'\n",
    "    'max_drawdown'\n",
    "    'combined'\n",
    "    \"\"\"\n",
    "    \n",
    "    optimized_by = 'annualized_return'\n",
    "    \n",
    "    \n",
    "    # Sort by Sharpe ratio\n",
    "    sorted_results = sorted(results, key=lambda x: x[optimized_by], reverse=True)\n",
    "    \n",
    "    # Best configuration\n",
    "    top_k = 10\n",
    "    top_configs = sorted_results[:top_k]\n",
    "    df = pd.DataFrame(top_configs)\n",
    "    best = df.mean(numeric_only=True)\n",
    "    value_arr = np.zeros(len(best))\n",
    "    \n",
    "    print(\"\\nBest configuration:\")\n",
    "    for i, (k, v) in enumerate(best.items()):\n",
    "        print(f\"{k:20s}: {v:.4f}\")\n",
    "        value_arr[i] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "0856c23e-5061-4af9-beb7-94b4c0706333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0005, grad_fn=<MeanBackward0>) tensor(0.8977, grad_fn=<MeanBackward0>) tensor(3.0024, grad_fn=<MeanBackward0>)\n",
      "\n",
      "<========== Final Test Performance ==========>\n",
      "Final cumulative return: 8.24%\n",
      "Annualized return: 13.93%\n",
      "Sharpe ratio: 0.98\n",
      "Max drawdown: -14.23%\n",
      "\n",
      "<========== S&P 500 Performance ==========>\n",
      "Final cumulative return: 11.18%\n",
      "Annualized return: 18.9%\n",
      "Sharpe ratio: 1.40\n",
      "Max drawdown: -8%\n",
      "\n",
      "Optimized by: annualized_return\n",
      "Number of samples: 153\n",
      "\n",
      "<========== Bootstrap results ==========>\n",
      "Daily Return: 0.05% [-0.09%, 0.19%]\n",
      "Cumulative Return: 8.48% [-13.68%, 33.76%]\n",
      "Annualized Return: 15.18% [-21.53%, 61.46%]\n",
      "Sharpe Ratio: 102.34% [-143.63%, 390.79%]\n",
      "Max Drawdown: -9.86% [-20.13%, -3.83%]\n"
     ]
    }
   ],
   "source": [
    "best_cash_threshold, best_temp, best_min_prob, best_max_loss, best_invest_sigmoid_scale = [0.05, 0.01, 0.01, 0.05, 5]\n",
    "\n",
    "all_returns = []  # Store all daily returns in time order\n",
    "\n",
    "total_ret, sample_count = 0, 0\n",
    "for test_x, test_y in test_loader:\n",
    "    test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "    mu, sigma, nu, dist_weights = model(test_x)\n",
    "\n",
    "    # === Apply current threshold to get allocation and returns ===\n",
    "    alloc, port_ret = calc_alloc_return(\n",
    "        mu, sigma, nu, dist_weights, test_y,\n",
    "        cash_threshold=best_cash_threshold,\n",
    "        temp=best_temp,\n",
    "        apply_confidence_mask=True,\n",
    "        min_prob=best_min_prob,\n",
    "        max_loss=best_max_loss,\n",
    "        invest_sigmoid_scale=best_invest_sigmoid_scale,\n",
    "        allow_short=True\n",
    "    )\n",
    "\n",
    "    total_ret += port_ret.sum().item()\n",
    "    sample_count += port_ret.shape[0]\n",
    "\n",
    "    all_returns.extend(port_ret.detach().cpu().numpy().flatten())\n",
    "\n",
    "print(mu.mean(), sigma.mean(), nu.mean())\n",
    "\n",
    "avg_daily_ret = total_ret / sample_count\n",
    "annual_ret = ((avg_daily_ret + 1)**252 - 1) * 100  # Trading year  252 days\n",
    "\n",
    "# Convert to numpy array\n",
    "all_returns = np.array(all_returns)  # shape: [n_days]\n",
    "\n",
    "# Cumulative equity (compound growth)\n",
    "equity_curve = np.cumprod(1 + all_returns)\n",
    "\n",
    "# Annualized return\n",
    "annualized_return = (equity_curve[-1]) ** (252 / len(equity_curve)) - 1\n",
    "\n",
    "# Sharpe ratio (assume 0% risk-free rate)\n",
    "sharpe_ratio = np.mean(all_returns) / (np.std(all_returns) + 1e-8) * np.sqrt(252)\n",
    "\n",
    "# Max drawdown\n",
    "rolling_max = np.maximum.accumulate(equity_curve)\n",
    "drawdowns = (equity_curve - rolling_max) / rolling_max\n",
    "max_drawdown = drawdowns.min()\n",
    "\n",
    "print(f\"\\n<========== Final Test Performance ==========>\")\n",
    "print(f\"Final cumulative return: {equity_curve[-1] - 1:.2%}\")\n",
    "print(f\"Annualized return: {annualized_return:.2%}\")\n",
    "print(f\"Sharpe ratio: {sharpe_ratio:.2f}\")\n",
    "print(f\"Max drawdown: {max_drawdown:.2%}\")\n",
    "\n",
    "print(f\"\\n<========== S&P 500 Performance ==========>\")\n",
    "print(f\"Final cumulative return: {0.285 * len(equity_curve) / 390:.2%}\")\n",
    "print(f\"Annualized return: 18.9%\")\n",
    "print(f\"Sharpe ratio: 1.40\")\n",
    "print(f\"Max drawdown: -8%\")\n",
    "print()\n",
    "print(f\"Optimized by: {optimized_by}\")\n",
    "print(f\"Number of samples: {len(equity_curve)}\")\n",
    "\n",
    "print(f\"\\n<========== Bootstrap results ==========>\")\n",
    "results = compute_performance_metrics(all_returns, n_bootstrap=1000, ci=0.95)\n",
    "for name, (mean_val, low, high) in results.items():\n",
    "    print(f\"{name.replace('_', ' ').title()}: {mean_val*100:.2f}% \"\n",
    "          f\"[{low*100:.2f}%, {high*100:.2f}%]\")\n",
    "\n",
    "#print(alloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05e198-1096-44cb-9b0f-50e2a02587c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
