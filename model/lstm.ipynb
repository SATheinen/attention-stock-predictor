{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "34300ad0-617f-416d-b249-8d7c6b16ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import StudentT\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from collections import defaultdict\n",
    "from random import uniform\n",
    "from tqdm import tqdm\n",
    "import scipy.stats\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "e93dcfe3-eed6-47c1-96eb-2e01c8b9e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatioTemporalCausalAttention(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_assets, num_timesteps):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(input_dim, embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.output_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.num_assets = num_assets\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        # Precompute causal time mask\n",
    "        t = num_timesteps\n",
    "        a = num_assets\n",
    "        time_ids = torch.arange(t).repeat(a)  # [A*T]\n",
    "        mask = time_ids[None, :] <= time_ids[:, None]\n",
    "        self.register_buffer(\"causal_mask\", (~mask).float() * float('-inf'))  # [A*T, A*T]\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, A, T, V = x.shape\n",
    "        x = x.permute(0, 2, 1, 3).reshape(B, A*T, V)  # [B, A*T, V]\n",
    "        x = self.embed(x)\n",
    "    \n",
    "        # Recreate the mask dynamically in case T is variable\n",
    "        time_ids = torch.arange(T, device=x.device).repeat(A)\n",
    "        mask = time_ids[None, :] <= time_ids[:, None]\n",
    "        causal_mask = (~mask).float() * float('-1e9')  # [A*T, A*T]\n",
    "    \n",
    "        attn_out, _ = self.attn(x, x, x, attn_mask=causal_mask)\n",
    "        x_proj = self.output_proj(attn_out)\n",
    "        \n",
    "        return x_proj.reshape(B, T, A, -1).permute(0, 2, 1, 3)  # [B, A, T, E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "796046ce-141d-49e1-bdf0-cca2085ab942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTimescaleLSTM(nn.Module):\n",
    "    def __init__(self, asset_size, h_size, n_layers, batch_size, seq_len,\n",
    "                 pre_heads, time_heads, asset_heads, num_studentT,\n",
    "                 value_size, dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.asset_out_size = asset_size\n",
    "        self.value_size = value_size\n",
    "        self.h_size = h_size\n",
    "        self.seq_len = seq_len\n",
    "        self.num_studentT = num_studentT\n",
    "\n",
    "        # === Attention Modules ===\n",
    "        self.spatio_temporal_attn = SpatioTemporalCausalAttention(\n",
    "            input_dim=value_size,\n",
    "            embed_dim=h_size,\n",
    "            num_heads=pre_heads,\n",
    "            num_assets=asset_size,\n",
    "            num_timesteps=seq_len\n",
    "        )\n",
    "\n",
    "        self.temporal_attn = nn.MultiheadAttention(embed_dim=h_size, num_heads=time_heads, batch_first=True)\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim=h_size, num_heads=asset_heads, batch_first=True)\n",
    "\n",
    "        # === LSTM ===\n",
    "        self.lstm = nn.LSTM(\n",
    "            #input_size=asset_size * h_size,\n",
    "            input_size=asset_size * value_size,\n",
    "            hidden_size=h_size,\n",
    "            num_layers=n_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # === Linear Layers ===\n",
    "        self.post_fc = nn.Linear(asset_size * h_size, 4 * asset_size * num_studentT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, A, V, T]\n",
    "        \"\"\"\n",
    "        B, A, V, T = x.shape\n",
    "        H = self.h_size\n",
    "        #x = x.transpose(2, 3)  # -> [B, A, T, V]\n",
    "\n",
    "        # === Spatio-Temporal Attention ===\n",
    "        #x_attn = self.spatio_temporal_attn(x)  # [B, A, T, H]\n",
    "        #x_attn = x_attn.transpose(1, 2)          # [B, T, A, H]\n",
    "        #B, T, A, H = x_attn.shape\n",
    "        #x_flat = x_attn.reshape(B, T, A * H)     # [B, T, A*H]\n",
    "        x = x.transpose(1, 3)\n",
    "        x_flat = x.reshape(B, T, A*V)\n",
    "\n",
    "        # === LSTM ===\n",
    "        lstm_out, _ = self.lstm(x_flat)          # [B, T, H]\n",
    "\n",
    "        # === Temporal Attention with Causal Mask ===\n",
    "        device = lstm_out.device\n",
    "        causal_mask = torch.triu(torch.full((T, T), float('-inf')), diagonal=1).to(device)\n",
    "        temp_out, _ = self.temporal_attn(lstm_out, lstm_out, lstm_out, attn_mask=causal_mask)\n",
    "\n",
    "        # === Cross-Asset Attention ===\n",
    "        final_state = temp_out[:, -1, :]                  # [B, H]\n",
    "        expanded = final_state.unsqueeze(1).repeat(1, A, 1)  # [B, A, H]\n",
    "        asset_out, _ = self.cross_attn(expanded, expanded, expanded)  # [B, A, H]\n",
    "        asset_flat = asset_out.reshape(B, A * H)          # [B, A*H]\n",
    "\n",
    "        final = self.post_fc(asset_flat) # [B, A*5]\n",
    "        final = final.view(B, A, 4, self.num_studentT)\n",
    "\n",
    "        # === Output Parameters ===\n",
    "        # [B, A, K]\n",
    "        mu       = final[:, :, 0, :]\n",
    "        log_sigma = final[:, :, 1, :]\n",
    "        log_nu    = final[:, :, 2, :]\n",
    "        dist_weights = final[:, :, 3, :]\n",
    "\n",
    "        sigma = torch.exp(log_sigma)# + 0.01\n",
    "        nu = torch.exp(log_nu)# + 2.0\n",
    "        dist_weights = torch.softmax(dist_weights, dim=-1)\n",
    "\n",
    "        return mu, sigma, nu, dist_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "4174cf13-7f92-4b0e-af0e-d9c935698254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Define evaluation points from 0 to 10\\nx = torch.linspace(-1, 1, 1000)  # shape [1000]\\n\\nmu = torch.zeros_like(x) + 0.13\\nsig = torch.zeros_like(x) + 0.35\\nnu = torch.zeros_like(x) + 3.45\\ndist_weights = torch.zeros_like(x) + 3.45\\n\\n# Compute log-PDF and exponentiate\\nlog_pdf = mixture_student_t_logpdf(x, mu, sig, nu, dist_weights)\\npdf = torch.exp(log_pdf)\\n\\n# Numerical integration over [0, 10]\\narea = torch.trapz(pdf, x)\\nprint(\"Integral over [0, 10]:\", area.item())\\n\\n# Plot\\nplt.plot(x, pdf)\\nplt.title(\"PDF on [0, 10]\")\\nplt.grid()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mixture_student_t_logpdf(x, mus, sigmas, nus, dist_weights):\n",
    "    \"\"\"\n",
    "    Log-likelihood of Mixture of Student-t Distributions.\n",
    "\n",
    "    Inputs:\n",
    "        x:        [B, A]         target returns\n",
    "        mus:      [B, A, K]      mixture component means\n",
    "        sigmas:   [B, A, K]      std deviations (must be positive)\n",
    "        nus:      [B, A, K]      degrees of freedom (must be > 2)\n",
    "        weights:  [B, A, K]      unnormalized weights\n",
    "\n",
    "    Returns:\n",
    "        log_prob: [B, A]         log-likelihood of each sample\n",
    "    \"\"\"\n",
    "    x = x.unsqueeze(-1).expand_as(mus)  # [B, A, K]\n",
    "    t_dist = StudentT(loc=mus, scale=sigmas, df=nus)\n",
    "    log_pdf = t_dist.log_prob(x)  # [B, A, K]\n",
    "    log_w = F.log_softmax(dist_weights, dim=-1)  # [B, A, K]\n",
    "    return torch.logsumexp(log_pdf + log_w, dim=-1)  # [B, A]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Define evaluation points from 0 to 10\n",
    "x = torch.linspace(-1, 1, 1000)  # shape [1000]\n",
    "\n",
    "mu = torch.zeros_like(x) + 0.13\n",
    "sig = torch.zeros_like(x) + 0.35\n",
    "nu = torch.zeros_like(x) + 3.45\n",
    "dist_weights = torch.zeros_like(x) + 3.45\n",
    "\n",
    "# Compute log-PDF and exponentiate\n",
    "log_pdf = mixture_student_t_logpdf(x, mu, sig, nu, dist_weights)\n",
    "pdf = torch.exp(log_pdf)\n",
    "\n",
    "# Numerical integration over [0, 10]\n",
    "area = torch.trapz(pdf, x)\n",
    "print(\"Integral over [0, 10]:\", area.item())\n",
    "\n",
    "# Plot\n",
    "plt.plot(x, pdf)\n",
    "plt.title(\"PDF on [0, 10]\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "54ba9e53-1761-4162-a899-959a46bcb682",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "def mixture_student_t_loss(mu, sigma, nu, dist_weights, target, deviation=(100., 0.)):\n",
    "    logp = mixture_student_t_logpdf(target, mu, sigma, nu, dist_weights)\n",
    "    loss = -logp\n",
    "    loss = torch.where(((torch.abs(target) < deviation[0]) & (torch.abs(target) > deviation[1])), loss, 0)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "8e01c2b5-9eec-4978-b90b-e7d57966afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataset():\n",
    "    def __init__(self, root_dir, seq_len=1024):\n",
    "        self.seq_len = seq_len\n",
    "        self.root_dir = root_dir\n",
    "        self.files = self.get_filenames()\n",
    "        self.data = self.load_data()\n",
    "\n",
    "    def get_filenames(self):\n",
    "        files = os.listdir(self.root_dir)\n",
    "        return files\n",
    "    \n",
    "    def load_data(self):\n",
    "        # Array of dimension [stock name, price category(open, close, high, low, close, volume, date), sequence length]\n",
    "        data = np.zeros((len(self.files), 7, self.seq_len))\n",
    "        \n",
    "        for i, filename in enumerate(self.files):\n",
    "            \n",
    "            with open(self.root_dir + '/' + filename, 'r', encoding=\"utf-8\") as file:\n",
    "                #print(filename)\n",
    "                #head = file.read(1000)\n",
    "                #print(head)  # if this looks binary, it's not a JSON file!\n",
    "                file.seek(0)\n",
    "                content = json.load(file)\n",
    "                time_series = content[\"Time Series (Daily)\"]\n",
    "\n",
    "                df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "                df.columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "                o = df[['open']].to_numpy()\n",
    "                c = df[['close']].to_numpy()\n",
    "                h = df[['high']].to_numpy()\n",
    "                l = df[['low']].to_numpy()\n",
    "                v = df[['volume']].to_numpy()\n",
    "                t = df.index.to_numpy()\n",
    "\n",
    "                # All data is aranged from oldest to newest date\n",
    "                # So we first have to flip the data by [::-1]\n",
    "                data[i, 0, :] = o.flatten()[:self.seq_len][::-1] / o.flatten()[1:self.seq_len + 1][::-1] - 1\n",
    "                data[i, 1, :] = c.flatten()[:self.seq_len][::-1] / c.flatten()[1:self.seq_len + 1][::-1] - 1\n",
    "                data[i, 2, :] = h.flatten()[:self.seq_len][::-1] / h.flatten()[1:self.seq_len + 1][::-1] - 1\n",
    "                data[i, 3, :] = l.flatten()[:self.seq_len][::-1] / l.flatten()[1:self.seq_len + 1][::-1] - 1\n",
    "                data[i, 5, :] = v.flatten()[:self.seq_len][::-1] / v.flatten()[self.seq_len + 1]\n",
    "\n",
    "                # convert date to unix time\n",
    "                dates = t.flatten()[:self.seq_len][::-1]\n",
    "                data[i, 6, :] = dates.astype('datetime64[s]')\n",
    "                data[i, 6, :] = data[i, 6, :].astype('int64')\n",
    "\n",
    "                file.close()\n",
    "\n",
    "            # extra statistics\n",
    "            data[:, 4, :] = data[:, 2, :] - data[:, 3, :] # daily range high - low\n",
    "    \n",
    "        return data\n",
    "\n",
    "    def average(self, decay_fac=0.0):\n",
    "        \n",
    "        avg_arr = np.zeros_like(self.data)\n",
    "        \n",
    "        for i in range(self.seq_len):\n",
    "            exp_decay = np.exp(-decay_fac * np.arange(0, self.seq_len - i))\n",
    "            exp_decay = exp_decay[::-1]\n",
    "            exp_decay = np.expand_dims(exp_decay, axis=0)\n",
    "            exp_decay = np.expand_dims(exp_decay, axis=0)\n",
    "            exp_decay = np.repeat(exp_decay, repeats=len(self.files), axis=0)\n",
    "            exp_decay = np.repeat(exp_decay, repeats=5, axis=1)\n",
    "            avg_arr[:,:-1,i] = np.sum(self.data[:,:-1,i:] * exp_decay, axis=-1) / np.sum(exp_decay[:,:,:], axis=-1)\n",
    "        \n",
    "        avg_arr[:,-1,:] = self.data[:,-1,:].copy()\n",
    "\n",
    "        return avg_arr\n",
    "\n",
    "    def recons_absol(self):\n",
    "        # this function only provides a test to reconstruct the original shape of the stock prices\n",
    "        abs_data = np.zeros_like(self.data)\n",
    "        abs_data[:,:,0] = 1.\n",
    "        abs_data[:,-1,:] = self.data[:,-1,:]\n",
    "        # iterate over all timesteps after the first\n",
    "        for j in range(self.data.shape[2] - 1):\n",
    "            abs_data[:, :-1, j+1] = abs_data[:, :-1, j] * (1 + self.data[:, :-1, j])\n",
    "\n",
    "        return abs_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "bcc2e7c7-a241-446d-9836-df1b92c7c743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LMT.json', 'BMW.DE.json', 'FRE.DE.json', 'ENR.DE.json', 'DAI.DE.json', 'SAP.DE.json', 'DHER.DE.json', 'AAPL.json', 'HOT.DE.json', 'RHM.DE.json', 'BAYN.DE.json', 'MUV2.DE.json', 'BAS.DE.json', 'ADS.DE.json', 'DBK.DE.json', 'ALV.DE.json', 'SIE.DE.json', 'DTE.DE.json']\n",
      "[1.         1.02403846 1.0150641  ... 2.88461538 2.94679487 3.00320513]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/lhm9rkfd5mq5nqs778m806v40000gn/T/ipykernel_59747/2488137769.py:82: RuntimeWarning: overflow encountered in multiply\n",
      "  abs_data[:, :-1, j+1] = abs_data[:, :-1, j] * (1 + self.data[:, :-1, j])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#root_dir = \"/Users/silas/work/machine_learning/LSTM/data/data_dump\"\n",
    "root_dir = \"/Users/silas/work/machine_learning/LSTM/data/my_repo\"\n",
    "stock_data = StockDataset(root_dir, seq_len=1124)\n",
    "\n",
    "stock_nr = 3\n",
    "\n",
    "print(stock_data.files)\n",
    "#plt.plot(stock_data.data[stock_nr,-1,:], stock_data.data[stock_nr,0,:])\n",
    "\n",
    "abs_data = stock_data.recons_absol()\n",
    "x = abs_data[stock_nr,0,:]\n",
    "y = np.mean(abs_data[:,-1,:], axis=0)\n",
    "print(x)\n",
    "plt.plot(y, x)\n",
    "#plt.vlines([x[int(0.7*len(x))], x[int(0.85*len(x))]], 0, 1)\n",
    "plt.show()\n",
    "\n",
    "#average = stock_data.average()\n",
    "#plt.plot(average[stock_nr,-1,:], average[stock_nr,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "baf221e6-1961-432e-8573-4ddd1243f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_len, target_stock_idx):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[-1] - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[:, :, idx : idx + self.seq_len]\n",
    "        y = self.data[:, target_stock_idx, idx + self.seq_len]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "3f86ed9d-f7bf-483b-995c-9792f1b2a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series(data, train_ratio=0.7, val_ratio=0.15):\n",
    "    time_steps = data.shape[-1]\n",
    "    #print(f\"Time steps: {time_steps}\")\n",
    "    train_end = int(time_steps * train_ratio)\n",
    "    val_end = int(time_steps * (train_ratio + val_ratio))\n",
    "    return data[:, :, 0:train_end], data[:, :, train_end:val_end], data[:, :, val_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "da0b2f04-c713-41d2-a37c-3881f3bb7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warmup_cosine_scheduler(optimizer, warmup_steps, total_steps, lr_max):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return current_step / warmup_steps\n",
    "        else:\n",
    "            progress = (current_step - warmup_steps) / (total_steps - warmup_steps)\n",
    "            return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "    \n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "73d3ccc8-335f-4b2a-9256-c9835e0937a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_warmup_steps = 100\n",
    "dummy_total_steps = 1000\n",
    "dummy_lr = np.zeros(dummy_total_steps)\n",
    "dummy_steps = np.arange(0, dummy_total_steps, 1)\n",
    "\n",
    "for step in dummy_steps:\n",
    "    if step < dummy_warmup_steps:\n",
    "        dummy_lr[step] = step / dummy_warmup_steps\n",
    "    else:\n",
    "        progress = (step - dummy_warmup_steps) / (dummy_total_steps - dummy_warmup_steps)\n",
    "        dummy_lr[step] = 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "plt.plot(dummy_steps, dummy_lr)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "772d80f0-0d4f-4cfc-a752-edcb6dae7a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock dimension: (18, 7, 1124)\n",
      "Value size: 5\n"
     ]
    }
   ],
   "source": [
    "in_size = len(stock_data.files)\n",
    "data_pass = stock_data.data[:,:5,:]\n",
    "target_stock_idx = 1 # [open, close, high, low, volume, datetime]\n",
    "print(f\"Stock dimension: {stock_data.data.shape}\")\n",
    "value_size = data_pass.shape[1]\n",
    "print(f\"Value size: {value_size}\")\n",
    "\n",
    "# lstm model parameters\n",
    "h_size = 16\n",
    "n_layers = 3\n",
    "num_studentT = 2\n",
    "\n",
    "pre_heads = 2\n",
    "time_heads = 2\n",
    "asset_heads = 2\n",
    "\n",
    "dropout = 0.3\n",
    "seq_len = 64\n",
    "batch_size = 1\n",
    "deviation = (0.05, 0.0)\n",
    "\n",
    "# training lstm model\n",
    "warmup_steps = 5\n",
    "total_steps = 20\n",
    "lr_max=5e-6\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "816cf1fc-e09c-431b-9c04-1ad6d92cb9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: train=(18, 5, 786) val=(18, 5, 169) test=(18, 5, 169)\n"
     ]
    }
   ],
   "source": [
    "train, val, test = split_time_series(data_pass, train_ratio=0.7, val_ratio=0.15)\n",
    "print(f\"Shapes: train={train.shape} val={val.shape} test={test.shape}\")\n",
    "\n",
    "train_ds = TimeSeriesDataset(train, seq_len, target_stock_idx)\n",
    "val_ds = TimeSeriesDataset(val, seq_len, target_stock_idx)\n",
    "test_ds = TimeSeriesDataset(test, seq_len, target_stock_idx)\n",
    "#print(f\"Shapes: train={train.shape} val={val.shape} test={test.shape}\")\n",
    "\n",
    "# (Batch, in_size, seq_len)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "8cac5b04-acd6-4299-b9be-26dabf0ba788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "70043128-d186-4136-a5ed-1fa3cfa45ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTimescaleLSTM(in_size, h_size, n_layers, batch_size, seq_len, pre_heads, \n",
    "                           time_heads, asset_heads, num_studentT, value_size, dropout).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_max, weight_decay=weight_decay)\n",
    "scheduler = get_warmup_cosine_scheduler(optimizer, warmup_steps=warmup_steps, total_steps=total_steps, lr_max=lr_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "a8b64e1b-a8a9-4e93-aacd-c6f480454005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_correct_preds(test_data, mu, sigma, nu, dist_weights, threshold):\n",
    "\n",
    "    sigma = np.where(nu > 2, np.sqrt(nu / (nu-2)) * sigma, 1e10)\n",
    "    \n",
    "    # signal to noise ratio\n",
    "    s_n = np.abs(mu) / sigma\n",
    "\n",
    "    significant_out = np.where(s_n > threshold, np.where(mu > 0, 1, -1), 0.)\n",
    "\n",
    "    samples = np.sum((significant_out * test_data) != 0)\n",
    "    correct_sign = np.sum((significant_out * test_data) > 0.)\n",
    "\n",
    "    return samples, correct_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "77f97ff2-8da7-456c-84b2-26c96453bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alloc_return(\n",
    "    mu, sigma, nu, dist_weights, real_returns,\n",
    "    cash_threshold=0.3,\n",
    "    temp=1.0,\n",
    "    apply_confidence_mask=True,\n",
    "    min_prob=0.1,\n",
    "    max_loss=0.05,\n",
    "    invest_sigmoid_scale=10.0,\n",
    "    allow_short=True\n",
    "):\n",
    "    B, A, K = mu.shape\n",
    "    device = mu.device\n",
    "\n",
    "    # Add 'cash' asset\n",
    "    mu = torch.cat([mu, torch.zeros(B, 1, K, device=device)], dim=1)\n",
    "    sigma = torch.cat([sigma, torch.ones(B, 1, K, device=device)], dim=1)\n",
    "    nu = torch.cat([nu, torch.full((B, 1, K), 10.0, device=device)], dim=1)\n",
    "    dist_weights = torch.cat([dist_weights, torch.full((B, 1, K), 1e-9, device=device)], dim=1)\n",
    "    real_returns = torch.cat([real_returns, torch.zeros(B, 1, device=device)], dim=1)\n",
    "\n",
    "    def mix_pdf(x_grid):\n",
    "        x = x_grid[:, None, None, None]  # [X, 1, 1, 1]\n",
    "        dist = StudentT(loc=mu[None], scale=sigma[None], df=nu[None])\n",
    "        pdf = dist.log_prob(x).exp()\n",
    "        return (dist_weights[None] * pdf).sum(dim=-1)  # [X, B, A+1]\n",
    "\n",
    "    def integrate(x, y):\n",
    "        return torch.trapz(y, x, dim=0)\n",
    "\n",
    "    x_grid = torch.linspace(-10, 10, 1000, device=device)\n",
    "    pdf = mix_pdf(x_grid)\n",
    "    pos_prob = integrate(x_grid, pdf * (x_grid > 0).float()[:, None, None])\n",
    "    exp_gain = integrate(x_grid, pdf * x_grid[:, None, None])\n",
    "\n",
    "    #x_loss = torch.linspace(-10, -float(max_loss), 1000, device=device)\n",
    "    #pdf_loss = mix_pdf(x_loss)\n",
    "    #loss_prob = integrate(x_loss, pdf_loss)\n",
    "\n",
    "    pos_prob[:, -1] = cash_threshold\n",
    "    if apply_confidence_mask:\n",
    "        #min_prob = min_prob.view(-1, 1)\n",
    "        pos_prob *= (pos_prob.abs() > min_prob).float()\n",
    "    #pos_prob *= (loss_prob < max_loss).float()\n",
    "\n",
    "    alloc_raw = F.softmax(pos_prob / temp, dim=-1)\n",
    "    mu_mean = mu.mean(dim=2)\n",
    "    max_sig = pos_prob[:, :-1].max(dim=1, keepdim=True)[0]\n",
    "    invest_ratio = torch.sigmoid((max_sig - cash_threshold) * invest_sigmoid_scale)\n",
    "    allocations = alloc_raw * invest_ratio\n",
    "\n",
    "    returns = torch.where(mu_mean > 0, real_returns, -real_returns) if allow_short else real_returns * (mu_mean > 0).float()\n",
    "    port_ret = (allocations * returns).sum(dim=1)\n",
    "    return allocations, port_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "26955d0c-8565-4984-90d7-7a4658bf64f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step              : 2/20\n",
      "LR in millions    : 20.000\n",
      "Train Loss        : 1.0848\n",
      "Validation Loss   : 1.0858\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 0.00%\n",
      "Annualized return: 0.00%\n",
      "Sharpe ratio: 0.00\n",
      "Max drawdown: 0.00%\n",
      "mu: -0.01 [-0.06, 0.07]\n",
      "sigma: 0.98 [0.92, 1.07]\n",
      "nu: 1.02 [0.95, 1.08]\n",
      "\n",
      "Step              : 4/20\n",
      "LR in millions    : 40.000\n",
      "Train Loss        : 0.9987\n",
      "Validation Loss   : 0.9411\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 0.00%\n",
      "Annualized return: 0.00%\n",
      "Sharpe ratio: 0.00\n",
      "Max drawdown: 0.00%\n",
      "mu: -0.00 [-0.02, 0.02]\n",
      "sigma: 0.87 [0.79, 0.99]\n",
      "nu: 1.14 [1.01, 1.28]\n",
      "\n",
      "Step              : 6/20\n",
      "LR in millions    : 49.454\n",
      "Train Loss        : 0.2505\n",
      "Validation Loss   : -0.2337\n",
      "<========== Quick Validation set Performance ==========>\n",
      "Final cumulative return: 0.00%\n",
      "Annualized return: 0.00%\n",
      "Sharpe ratio: 0.00\n",
      "Max drawdown: 0.00%\n",
      "mu: 0.00 [-0.00, 0.01]\n",
      "sigma: 0.32 [0.21, 0.51]\n",
      "nu: 2.87 [1.82, 4.20]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[366], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m mu, sigma, nu, dist_weights \u001b[38;5;241m=\u001b[39m model(batch_x)\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m mixture_student_t_loss(mu, sigma, nu, dist_weights, batch_y, deviation)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/work/machine_learning/transformer/venv/lib/python3.9/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/machine_learning/transformer/venv/lib/python3.9/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/machine_learning/transformer/venv/lib/python3.9/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_cash_threshold = 0.05\n",
    "train_temp = 0.01\n",
    "train_min_prob = 0.01\n",
    "train_max_loss = 0.05\n",
    "train_invest_sigmoid_scale = 5\n",
    "\n",
    "# Train LSTM model\n",
    "for step in range(total_steps):\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # train stock predictor\n",
    "        optimizer.zero_grad()\n",
    "        mu, sigma, nu, dist_weights = model(batch_x)\n",
    "        loss = mixture_student_t_loss(mu, sigma, nu, dist_weights, batch_y, deviation)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    if (step % 2 == 1):\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        all_returns = []\n",
    "        total_ret, sample_count = 0, 0\n",
    "    \n",
    "        for val_x, val_y in val_loader:\n",
    "            val_x = val_x.to(device)\n",
    "            val_y = val_y.to(device)\n",
    "    \n",
    "            mu, sigma, nu, dist_weights = model(val_x)\n",
    "            loss = mixture_student_t_loss(mu, sigma, nu, dist_weights, val_y, deviation)\n",
    "    \n",
    "            val_loss += loss.item()\n",
    "    \n",
    "            # === Apply current threshold to get allocation and returns ===\n",
    "            alloc, port_ret = calc_alloc_return(\n",
    "                mu, sigma, nu, dist_weights, val_y,\n",
    "                cash_threshold=train_cash_threshold,\n",
    "                temp=train_temp,\n",
    "                apply_confidence_mask=True,\n",
    "                min_prob=train_min_prob,\n",
    "                max_loss=train_max_loss,\n",
    "                invest_sigmoid_scale=train_invest_sigmoid_scale,\n",
    "                allow_short=True\n",
    "            )\n",
    "        \n",
    "            total_ret += port_ret.sum().item()\n",
    "            sample_count += port_ret.shape[0]\n",
    "        \n",
    "            all_returns.extend(port_ret.detach().cpu().numpy().flatten())\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"Weights: \", dist_weights)\n",
    "        print(\"mu: \", mu)\n",
    "        print(\"sigma: \", sigma)\n",
    "        print(\"nu: \", nu)\n",
    "        \"\"\"\n",
    "            \n",
    "        avg_daily_ret = total_ret / sample_count\n",
    "        annual_ret = ((avg_daily_ret + 1)**252 - 1) * 100  # Trading year ≈ 252 days\n",
    "    \n",
    "        # Convert to numpy array\n",
    "        all_returns = np.array(all_returns)  # shape: [n_days]\n",
    "        \n",
    "        # Cumulative equity (compound growth)\n",
    "        equity_curve = np.cumprod(1 + all_returns)\n",
    "        \n",
    "        # Annualized return\n",
    "        annualized_return = (equity_curve[-1]) ** (252 / len(equity_curve)) - 1\n",
    "        \n",
    "        # Sharpe ratio (assume 0% risk-free rate)\n",
    "        sharpe_ratio = np.mean(all_returns) / (np.std(all_returns) + 1e-8) * np.sqrt(252)\n",
    "        \n",
    "        # Max drawdown\n",
    "        rolling_max = np.maximum.accumulate(equity_curve)\n",
    "        drawdowns = (equity_curve - rolling_max) / rolling_max\n",
    "        max_drawdown = drawdowns.min()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Step              : {step+1}/{total_steps}\")\n",
    "        print(f\"LR in millions    : {scheduler.get_last_lr()[0]*10e6:.3f}\")\n",
    "        print(f\"Train Loss        : {avg_train_loss:.4f}\")\n",
    "        print(f\"Validation Loss   : {avg_val_loss:.4f}\")\n",
    "        print(f\"<========== Quick Validation set Performance ==========>\")\n",
    "        print(f\"Final cumulative return: {equity_curve[-1] - 1:.2%}\")\n",
    "        print(f\"Annualized return: {annualized_return:.2%}\")\n",
    "        print(f\"Sharpe ratio: {sharpe_ratio:.2f}\")\n",
    "        print(f\"Max drawdown: {max_drawdown:.2%}\")\n",
    "        print(f\"mu: {mu.mean():.2f} [{mu.min():.2f}, {mu.max():.2f}]\")\n",
    "        print(f\"sigma: {sigma.mean():.2f} [{sigma.min():.2f}, {sigma.max():.2f}]\")\n",
    "        print(f\"nu: {nu.mean():.2f} [{nu.min():.2f}, {nu.max():.2f}]\")\n",
    "        #print(f\"Weights: {dist_weights.item():.2f}\")\n",
    "        #print(f\"Significant points: {samples}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd9057-bc5e-48cf-8d71-f47d359d89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performance_metrics(returns, n_bootstrap=1000, ci=0.95):\n",
    "    \"\"\"\n",
    "    Computes metrics and confidence intervals via bootstrapping.\n",
    "    Args:\n",
    "        returns: array-like, daily returns\n",
    "        n_bootstrap: number of resampling iterations\n",
    "        ci: confidence level (default: 95%)\n",
    "    Returns:\n",
    "        Dict of metric -> (mean, lower_ci, upper_ci)\n",
    "    \"\"\"\n",
    "    returns = np.array(returns)\n",
    "    alpha = 1 - ci\n",
    "    metrics = {\n",
    "        'daily_return': [],\n",
    "        'cumulative_return': [],\n",
    "        'annualized_return': [],\n",
    "        'sharpe_ratio': [],\n",
    "        'max_drawdown': []\n",
    "    }\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(returns, size=len(returns), replace=True)\n",
    "\n",
    "        # === Metrics ===\n",
    "        mean_r = np.mean(sample)\n",
    "        std_r = np.std(sample)\n",
    "        sharpe = mean_r / (std_r + 1e-8) * np.sqrt(252)\n",
    "\n",
    "        # Cumulative equity curve\n",
    "        equity = np.cumprod(1 + sample)\n",
    "        cum_return = equity[-1] - 1\n",
    "        annual_ret = (equity[-1])**(252 / len(sample)) - 1\n",
    "\n",
    "        # Drawdown\n",
    "        peak = np.maximum.accumulate(equity)\n",
    "        dd = (equity - peak) / peak\n",
    "        max_dd = dd.min()\n",
    "\n",
    "        # Store\n",
    "        metrics['daily_return'].append(mean_r)\n",
    "        metrics['cumulative_return'].append(cum_return)\n",
    "        metrics['annualized_return'].append(annual_ret)\n",
    "        metrics['sharpe_ratio'].append(sharpe)\n",
    "        metrics['max_drawdown'].append(max_dd)\n",
    "\n",
    "    # Compute CI bounds\n",
    "    def summarize(metric_values):\n",
    "        mean_val = np.mean(metric_values)\n",
    "        lower = np.percentile(metric_values, 100 * alpha / 2)\n",
    "        upper = np.percentile(metric_values, 100 * (1 - alpha / 2))\n",
    "        return mean_val, lower, upper\n",
    "\n",
    "    return {k: summarize(v) for k, v in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "db6b4d55-e716-43e0-ae82-3f8b4ec3d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training allocation model\n",
    "a_warmup_steps = 20\n",
    "a_total_steps = 100\n",
    "a_lr_max=1e-5\n",
    "a_weight_decay = 0\n",
    "\n",
    "# Model parameters\n",
    "hidden_dim = 128\n",
    "embed_dim = 256\n",
    "proj_dim = 128\n",
    "dropout = 0.3\n",
    "\n",
    "# loss parameters\n",
    "cash_penalty_factor = 0.0\n",
    "diversity_penalty_factor = 0.0 #1e-6\n",
    "entropy_coeff = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "1d55ed30-2563-4454-9d53-bf2ee84c36f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class allocationModel(nn.Module):\n",
    "    def __init__(self, in_size, num_studentt, hidden_dim, embed_dim, proj_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_size = in_size\n",
    "        self.input_dim = 4 * in_size * num_studentt\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.proj_dim = proj_dim\n",
    "        self.pre_layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(self.hidden_dim, self.embed_dim)\n",
    "        )\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=self.embed_dim, num_heads=4, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.post_layers = nn.Sequential(\n",
    "            nn.Linear(self.embed_dim, self.proj_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(self.proj_dim, in_size + 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, A * 4 * num_studentt]\n",
    "        x = self.pre_layers(x)   # -> [B, A, 32]\n",
    "        attn_out, _ = self.attn(x, x, x)  # self-attention\n",
    "        attn_out = nn.LayerNorm(attn_out.shape[-1])(attn_out)\n",
    "        attn_out = self.dropout(attn_out)\n",
    "        out = self.post_layers(attn_out)  # -> [B, A, in_size + 1]\n",
    "        out = torch.softmax(out / 0.5, dim=-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "5bfd4c29-0bad-474a-9178-e10b550bd679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef allocation_loss(weights, target, cash_penalty_factor, diversity_penalty_factor):\\n\\n    cash_penalty = weights[:, -1].mean() * cash_penalty_factor\\n\\n    diversity_penalty = (weights[:, :-1] ** 2).sum(dim=1).mean() * diversity_penalty_factor\\n\\n    # x [B, A + 1] (The last weight represents no investment)\\n    total_return = (weights[:, :-1] * target).sum(dim=1) + weights[:, -1] * 0.0  # add cash return if > 0\\n\\n    loss = total_return + diversity_penalty + cash_penalty\\n    \\n    return -loss\\n'"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def allocation_loss(weights, target, cash_penalty_factor, diversity_penalty_factor):\n",
    "\n",
    "    cash_penalty = weights[:, -1].mean() * cash_penalty_factor\n",
    "\n",
    "    diversity_penalty = (weights[:, :-1] ** 2).sum(dim=1).mean() * diversity_penalty_factor\n",
    "\n",
    "    # x [B, A + 1] (The last weight represents no investment)\n",
    "    total_return = (weights[:, :-1] * target).sum(dim=1) + weights[:, -1] * 0.0  # add cash return if > 0\n",
    "\n",
    "    loss = total_return + diversity_penalty + cash_penalty\n",
    "    \n",
    "    return -loss\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "b6079f4a-979a-49e6-a34c-67d72b6e4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingSharpeLoss:\n",
    "    def __init__(self, window_size=100, eps=1e-6, cash_penalty=0.0, diversity_penalty=0.0, entropy_coeff=0.0):\n",
    "        self.window_size = window_size\n",
    "        self.returns = []  # buffer\n",
    "        self.eps = eps\n",
    "        self.cash_penalty = cash_penalty\n",
    "        self.diversity_penalty = diversity_penalty\n",
    "\n",
    "    def __call__(self, weights, target):\n",
    "        # Compute portfolio return\n",
    "        port_return = (weights[:, :-1] * target).sum(dim=1).item()  # scalar\n",
    "\n",
    "        self.returns.append(port_return)\n",
    "        if len(self.returns) > self.window_size:\n",
    "            self.returns.pop(0)\n",
    "\n",
    "        if len(self.returns) < 2:\n",
    "            # not enough data to compute Sharpe\n",
    "            sharpe = 0.0\n",
    "        else:\n",
    "            r = torch.tensor(self.returns)\n",
    "            sharpe = r.mean() / (r.std(unbiased=False) + self.eps)\n",
    "\n",
    "        # Penalties\n",
    "        cash_pen = weights[:, -1].mean() * self.cash_penalty\n",
    "        diversity_pen = (weights[:, :-1] ** 2).sum(dim=1).mean() * self.diversity_penalty\n",
    "        entropy = -torch.sum(weights * torch.log(weights + 1e-8), dim=1).mean()\n",
    "\n",
    "        return -sharpe -entropy_coeff * entropy + cash_pen + diversity_pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "199c77ab-2513-4002-b47c-088085fa39b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "allocation_model = allocationModel(in_size, num_studentT, hidden_dim, embed_dim, proj_dim, dropout)\n",
    "allocation_optimizer = torch.optim.Adam(allocation_model.parameters(), lr=a_lr_max, weight_decay=a_weight_decay)\n",
    "allocation_scheduler = get_warmup_cosine_scheduler(allocation_optimizer, warmup_steps=a_warmup_steps, total_steps=a_total_steps, lr_max=a_lr_max)\n",
    "allocation_loss = RollingSharpeLoss(window_size=10, eps=1e-6, cash_penalty=cash_penalty_factor, diversity_penalty=diversity_penalty_factor, entropy_coeff=entropy_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "68d28e84-9de1-47da-a510-3758418f27c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step              : 5/100\n",
      "LR in millions    : 25.000\n",
      "Validation loss   : -3.10833\n",
      "Test loss         : -3.05275\n",
      "Average Day return: 0.14%\n",
      "tensor([[0.0596, 0.0572, 0.0641, 0.0749, 0.0602, 0.0483, 0.0553, 0.0404, 0.0468,\n",
      "         0.0596, 0.0448, 0.0452, 0.0442, 0.0581, 0.0475, 0.0584, 0.0493, 0.0389,\n",
      "         0.0472]], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "Step              : 10/100\n",
      "LR in millions    : 50.000\n",
      "Validation loss   : -3.16758\n",
      "Test loss         : -3.05265\n",
      "Average Day return: 0.12%\n",
      "tensor([[0.0604, 0.0564, 0.0582, 0.0513, 0.0496, 0.0633, 0.0556, 0.0449, 0.0479,\n",
      "         0.0502, 0.0559, 0.0571, 0.0502, 0.0440, 0.0466, 0.0532, 0.0583, 0.0467,\n",
      "         0.0502]], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "Step              : 15/100\n",
      "LR in millions    : 75.000\n",
      "Validation loss   : -3.18165\n",
      "Test loss         : -3.05526\n",
      "Average Day return: 0.12%\n",
      "tensor([[0.0617, 0.0570, 0.0595, 0.0521, 0.0506, 0.0609, 0.0544, 0.0448, 0.0479,\n",
      "         0.0509, 0.0567, 0.0575, 0.0490, 0.0464, 0.0469, 0.0526, 0.0569, 0.0452,\n",
      "         0.0492]], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "Step              : 20/100\n",
      "LR in millions    : 100.000\n",
      "Validation loss   : -3.17749\n",
      "Test loss         : -3.06050\n",
      "Average Day return: 0.12%\n",
      "tensor([[0.0576, 0.0538, 0.0604, 0.0550, 0.0523, 0.0578, 0.0526, 0.0454, 0.0491,\n",
      "         0.0539, 0.0541, 0.0556, 0.0498, 0.0502, 0.0500, 0.0533, 0.0540, 0.0464,\n",
      "         0.0485]], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "Step              : 25/100\n",
      "LR in millions    : 99.039\n",
      "Validation loss   : -3.18169\n",
      "Test loss         : -3.05869\n",
      "Average Day return: 0.12%\n",
      "tensor([[0.0586, 0.0551, 0.0582, 0.0533, 0.0520, 0.0584, 0.0535, 0.0464, 0.0482,\n",
      "         0.0525, 0.0550, 0.0557, 0.0491, 0.0485, 0.0492, 0.0538, 0.0550, 0.0470,\n",
      "         0.0504]], grad_fn=<SoftmaxBackward0>)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[670], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m allocation_loss(output, y_val)\n\u001b[1;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mallocation_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     22\u001b[0m avg_val_loss \u001b[38;5;241m=\u001b[39m val_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(val_loader)\n",
      "File \u001b[0;32m~/work/machine_learning/transformer/venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:124\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    123\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/machine_learning/transformer/venv/lib/python3.9/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/work/machine_learning/transformer/venv/lib/python3.9/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/work/machine_learning/transformer/venv/lib/python3.9/site-packages/torch/optim/adam.py:246\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    234\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    236\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    237\u001b[0m         group,\n\u001b[1;32m    238\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         state_steps,\n\u001b[1;32m    244\u001b[0m     )\n\u001b[0;32m--> 246\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/work/machine_learning/transformer/venv/lib/python3.9/site-packages/torch/optim/optimizer.py:147\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/machine_learning/transformer/venv/lib/python3.9/site-packages/torch/optim/adam.py:933\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 933\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/machine_learning/transformer/venv/lib/python3.9/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    436\u001b[0m     device_beta1 \u001b[38;5;241m=\u001b[39m beta1\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_beta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# Nested if is necessary to bypass jitscript rules\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m differentiable \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta2, Tensor):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for a_step in range(a_total_steps):\n",
    "    \n",
    "    # Train model\n",
    "    allocation_model.train()\n",
    "\n",
    "    val_loss = 0\n",
    "    for x_val, y_val in val_loader:\n",
    "        \n",
    "        mu, sigma, nu, weights = model(x_val) # Each [B, A, K]\n",
    "        B, A, K = mu.shape\n",
    "        x = torch.cat([mu, sigma, nu, weights], dim=1) # [B, A * 4, K]\n",
    "        x = x.reshape(B, A * 4 * K)\n",
    "        \n",
    "        output = allocation_model(x)\n",
    "        loss = allocation_loss(output, y_val)\n",
    "\n",
    "        loss.backward()\n",
    "        allocation_optimizer.step()\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    allocation_scheduler.step()\n",
    "\n",
    "    # Test performance\n",
    "    allocation_model.eval()\n",
    "\n",
    "    returns = 0\n",
    "    test_loss = 0\n",
    "    for x_test, y_test in test_loader:\n",
    "\n",
    "        mu, sigma, nu, weights = model(x_test) # Each [B, A, K]\n",
    "        B, A, K = mu.shape\n",
    "        x = torch.cat([mu, sigma, nu, weights], dim=1) # [B, A * 4, K]\n",
    "        x = x.reshape(B, A * 4 * K)\n",
    "        \n",
    "        output = allocation_model(x)\n",
    "        loss = allocation_loss(output, y_test)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        returns += (output[:, :-1] * y_test).sum()\n",
    "    avg_returns = returns / len(test_loader)\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    if (a_step % 5 == 4):\n",
    "        print(f\"Step              : {a_step+1}/{a_total_steps}\")\n",
    "        print(f\"LR in millions    : {allocation_scheduler.get_last_lr()[0]*10e6:.3f}\")\n",
    "        print(f\"Validation loss   : {avg_val_loss:.5f}\")\n",
    "        print(f\"Test loss         : {avg_test_loss:.5f}\")\n",
    "        print(f\"Average Day return: {avg_returns * 100:.2}%\")\n",
    "        print(output)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b0edb-33f0-4731-a7be-1acd8d02c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "################################################\n",
    "################## Analyze #####################\n",
    "################################################\n",
    "################################################\n",
    "\n",
    "def sample_random_params():\n",
    "    return {\n",
    "        \"cash_threshold\": uniform(0.0, 0.05),\n",
    "        \"temp\": uniform(0.001, 0.1),\n",
    "        \"min_prob\": uniform(0.0, 1.0),\n",
    "        \"max_loss\": uniform(0.0, 0.1),\n",
    "        \"invest_sigmoid_scale\": uniform(1.0, 20.0)\n",
    "    }\n",
    "\n",
    "def evaluate_config(model, val_loader, config):\n",
    "    all_returns = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_x, val_y in val_loader:\n",
    "            val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "            mu, sigma, nu, dist_weights = model(val_x)\n",
    "\n",
    "            _, port_ret = calc_alloc_return(\n",
    "                mu, sigma, nu, dist_weights, val_y,\n",
    "                cash_threshold=config['cash_threshold'],\n",
    "                temp=config['temp'],\n",
    "                apply_confidence_mask=True,\n",
    "                min_prob=config['min_prob'],\n",
    "                max_loss=config['max_loss'],\n",
    "                invest_sigmoid_scale=config['invest_sigmoid_scale'],\n",
    "                allow_short=True\n",
    "            )\n",
    "\n",
    "            returns = port_ret.detach().cpu().numpy().flatten()\n",
    "            all_returns.extend(returns)\n",
    "\n",
    "    r = np.array(all_returns)\n",
    "    if len(r) < 10:  # not enough points for reliable metrics\n",
    "        return None\n",
    "\n",
    "    # Metrics\n",
    "    equity = np.cumprod(1 + r)\n",
    "    cumulative_return = equity[-1] - 1\n",
    "    annualized = (equity[-1])**(252 / len(r)) - 1\n",
    "    sharpe = np.mean(r) / (np.std(r) + 1e-8) * np.sqrt(252)\n",
    "    max_dd = (equity - np.maximum.accumulate(equity)) / np.maximum.accumulate(equity)\n",
    "    drawdown = max_dd.min()\n",
    "\n",
    "    return {\n",
    "        'sharpe': sharpe,\n",
    "        'annualized_return': annualized,\n",
    "        'cumulative_return': cumulative_return,\n",
    "        'max_drawdown': drawdown,\n",
    "        'samples': len(r),\n",
    "        'combined': 0.5 * sharpe + 2 * annualized - 1 * abs(drawdown)\n",
    "    }\n",
    "\n",
    "n_trials = 500\n",
    "results = []\n",
    "\n",
    "for _ in tqdm(range(n_trials)):\n",
    "    params = sample_random_params()\n",
    "    metrics = evaluate_config(model, val_loader, params)\n",
    "    if metrics:\n",
    "        results.append({\n",
    "            **params,\n",
    "            **metrics\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130dd32-2bfc-4515-b90a-c20023ccbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "'sharpe'\n",
    "'annualized_return'\n",
    "'cumulative_return'\n",
    "'max_drawdown'\n",
    "'combined'\n",
    "\"\"\"\n",
    "\n",
    "optimized_by = 'annualized_return'\n",
    "\n",
    "\n",
    "# Sort by Sharpe ratio\n",
    "sorted_results = sorted(results, key=lambda x: x[optimized_by], reverse=True)\n",
    "\n",
    "# Best configuration\n",
    "top_k = 10\n",
    "top_configs = sorted_results[:top_k]\n",
    "df = pd.DataFrame(top_configs)\n",
    "best = df.mean(numeric_only=True)\n",
    "value_arr = np.zeros(len(best))\n",
    "\n",
    "print(\"\\nBest configuration:\")\n",
    "for i, (k, v) in enumerate(best.items()):\n",
    "    print(f\"{k:20s}: {v:.4f}\")\n",
    "    value_arr[i] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856c23e-5061-4af9-beb7-94b4c0706333",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cash_threshold, best_temp, best_min_prob, best_max_loss, best_invest_sigmoid_scale = value_arr[0:5]\n",
    "\n",
    "all_returns = []  # Store all daily returns in time order\n",
    "\n",
    "total_ret, sample_count = 0, 0\n",
    "for test_x, test_y in test_loader:\n",
    "    test_x, test_y = test_x.to(device), test_y.to(device)\n",
    "    mu, sigma, nu, dist_weights = model(test_x)\n",
    "\n",
    "    # === Apply current threshold to get allocation and returns ===\n",
    "    alloc, port_ret = calc_alloc_return(\n",
    "        mu, sigma, nu, dist_weights, test_y,\n",
    "        cash_threshold=best_cash_threshold,\n",
    "        temp=best_temp,\n",
    "        apply_confidence_mask=True,\n",
    "        min_prob=best_min_prob,\n",
    "        max_loss=best_max_loss,\n",
    "        invest_sigmoid_scale=best_invest_sigmoid_scale,\n",
    "        allow_short=True\n",
    "    )\n",
    "\n",
    "    total_ret += port_ret.sum().item()\n",
    "    sample_count += port_ret.shape[0]\n",
    "\n",
    "    all_returns.extend(port_ret.detach().cpu().numpy().flatten())\n",
    "\n",
    "print(mu.mean(), sigma.mean(), nu.mean())\n",
    "\n",
    "avg_daily_ret = total_ret / sample_count\n",
    "annual_ret = ((avg_daily_ret + 1)**252 - 1) * 100  # Trading year ≈ 252 days\n",
    "\n",
    "# Convert to numpy array\n",
    "all_returns = np.array(all_returns)  # shape: [n_days]\n",
    "\n",
    "# Cumulative equity (compound growth)\n",
    "equity_curve = np.cumprod(1 + all_returns)\n",
    "\n",
    "# Annualized return\n",
    "annualized_return = (equity_curve[-1]) ** (252 / len(equity_curve)) - 1\n",
    "\n",
    "# Sharpe ratio (assume 0% risk-free rate)\n",
    "sharpe_ratio = np.mean(all_returns) / (np.std(all_returns) + 1e-8) * np.sqrt(252)\n",
    "\n",
    "# Max drawdown\n",
    "rolling_max = np.maximum.accumulate(equity_curve)\n",
    "drawdowns = (equity_curve - rolling_max) / rolling_max\n",
    "max_drawdown = drawdowns.min()\n",
    "\n",
    "print(f\"\\n<========== Final Test Performance ==========>\")\n",
    "#print(f\"Daily return @ threshold={final_th:.3f}: {avg_daily_ret*100:.3f}%\")\n",
    "#print(f\"Annualized return: {annual_ret:.2f}%\")\n",
    "#print()\n",
    "print(f\"Final cumulative return: {equity_curve[-1] - 1:.2%}\")\n",
    "print(f\"Annualized return: {annualized_return:.2%}\")\n",
    "print(f\"Sharpe ratio: {sharpe_ratio:.2f}\")\n",
    "print(f\"Max drawdown: {max_drawdown:.2%}\")\n",
    "\n",
    "print(f\"\\n<========== S&P 500 Performance ==========>\")\n",
    "print(f\"Final cumulative return: {0.285 * len(equity_curve) / 390:.2%}\")\n",
    "print(f\"Annualized return: 18.9%\")\n",
    "print(f\"Sharpe ratio: 1.40\")\n",
    "print(f\"Max drawdown: -8%\")\n",
    "print()\n",
    "print(f\"Optimized by: {optimized_by}\")\n",
    "print(f\"Number of samples: {len(equity_curve)}\")\n",
    "\n",
    "print(f\"\\n<========== Bootstrap results ==========>\")\n",
    "results = compute_performance_metrics(all_returns, n_bootstrap=1000, ci=0.95)\n",
    "for name, (mean_val, low, high) in results.items():\n",
    "    print(f\"{name.replace('_', ' ').title()}: {mean_val*100:.2f}% \"\n",
    "          f\"[{low*100:.2f}%, {high*100:.2f}%]\")\n",
    "\n",
    "#print(alloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05e198-1096-44cb-9b0f-50e2a02587c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
